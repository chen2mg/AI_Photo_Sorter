{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc06f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEIC/HEIF support enabled.\n",
      "Scanning directory: D:\\images\\HockingHills...\n",
      "--- Scan Complete ---\n",
      "Total image files found: 91\n",
      "Duplicate images skipped: 0\n",
      "Total unique images to process: 91\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "{'D:\\\\images\\\\HockingHills\\\\AILF6859.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\AKIU2926.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\APWO0546.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\BAXC5641.JPG': 'unknown', 'D:\\\\images\\\\HockingHills\\\\BWVB7885.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\DPTE4051.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\EKJO8625.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\EMXD5711.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\EUJU2177.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\FGCU1920.JPG': 'unknown', 'D:\\\\images\\\\HockingHills\\\\GAHE9208.JPG': 'people', 'D:\\\\images\\\\HockingHills\\\\HNSX6644.JPG': 'unknown', 'D:\\\\images\\\\HockingHills\\\\IMG_2596.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2598.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2600.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2601.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2602.HEIC': 'unknown', 'D:\\\\images\\\\HockingHills\\\\IMG_2603.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2604.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2605.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2606.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2607.HEIC': 'unknown', 'D:\\\\images\\\\HockingHills\\\\IMG_2608.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2609.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2610.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2612.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2613.HEIC': 'unknown', 'D:\\\\images\\\\HockingHills\\\\IMG_2614.HEIC': 'unknown', 'D:\\\\images\\\\HockingHills\\\\IMG_2615.HEIC': 'unknown', 'D:\\\\images\\\\HockingHills\\\\IMG_2616.HEIC': 'unknown', 'D:\\\\images\\\\HockingHills\\\\IMG_2617.HEIC': 'people', 'D:\\\\images\\\\HockingHills\\\\IMG_2618.HEIC': 'people'}\n",
      "D:\\images\\HockingHills\\AILF6859.JPG unknown people\n",
      "D:\\images\\HockingHills\\AKIU2926.JPG unknown people\n",
      "D:\\images\\HockingHills\\APWO0546.JPG unknown people\n",
      "D:\\images\\HockingHills\\BAXC5641.JPG unknown unknown\n",
      "D:\\images\\HockingHills\\BWVB7885.JPG unknown people\n",
      "D:\\images\\HockingHills\\DPTE4051.JPG unknown people\n",
      "D:\\images\\HockingHills\\EKJO8625.JPG unknown people\n",
      "D:\\images\\HockingHills\\EMXD5711.JPG unknown people\n",
      "D:\\images\\HockingHills\\EUJU2177.JPG unknown people\n",
      "D:\\images\\HockingHills\\FGCU1920.JPG unknown unknown\n",
      "D:\\images\\HockingHills\\GAHE9208.JPG unknown people\n",
      "D:\\images\\HockingHills\\HNSX6644.JPG unknown unknown\n",
      "D:\\images\\HockingHills\\IMG_2596.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2598.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2600.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2601.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2602.HEIC unknown unknown\n",
      "D:\\images\\HockingHills\\IMG_2603.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2604.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2605.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2606.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2607.HEIC unknown unknown\n",
      "D:\\images\\HockingHills\\IMG_2608.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2609.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2610.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2612.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2613.HEIC unknown unknown\n",
      "D:\\images\\HockingHills\\IMG_2614.HEIC unknown unknown\n",
      "D:\\images\\HockingHills\\IMG_2615.HEIC unknown unknown\n",
      "D:\\images\\HockingHills\\IMG_2616.HEIC unknown unknown\n",
      "D:\\images\\HockingHills\\IMG_2617.HEIC unknown people\n",
      "D:\\images\\HockingHills\\IMG_2618.HEIC unknown people\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import shutil\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Generator, Any\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "\n",
    "# --- HEIC/HEIF Support ---\n",
    "# This is required to make PIL.Image.open() support HEIC/HEIF formats.\n",
    "# You must install this library: pip install pillow-heif\n",
    "try:\n",
    "    import pillow_heif\n",
    "    pillow_heif.register_heif_opener()\n",
    "    print(\"HEIC/HEIF support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: 'pillow-heif' not installed. HEIC/HEIF files will be skipped.\")\n",
    "    print(\"Install with: pip install pillow-heif\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "try:\n",
    "    from insightface.app import FaceAnalysis\n",
    "    print(\"FaceAnalysis support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: FaceAnalysis not installed.\")\n",
    "    print(\"pip install insightface\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "# --- Hugging Face transformers ---\n",
    "# You must install this library: pip install transformers torch\n",
    "try:\n",
    "    from transformers import pipeline, Pipeline\n",
    "    from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"CRITICAL: 'transformers' or 'torch' not found.\")\n",
    "    print(\"Please install them to run this script: pip install transformers torch\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "class ImageDataloader:\n",
    "    \"\"\"\n",
    "    Scans a directory for unique images and provides batches for processing.\n",
    "\n",
    "    This class is implemented as a Python generator. It does not\n",
    "    inherit from torch.utils.data.DataLoader, as our use case\n",
    "    requires a simple, stateful iterator.\n",
    "    \"\"\"\n",
    "    IMAGE_EXTENSIONS: tuple = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "\n",
    "    def __init__(self, root_dir: str, batch_size: int = 32):\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"Root directory not found: {root_dir}\")\n",
    "        if batch_size <= 0:\n",
    "            raise ValueError(\"Batch size must be greater than 0\")\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.labels will hold the \"working state\" of all images\n",
    "        # {image_path: \"unknown\"}\n",
    "        self.labels: Dict[str, str] = {}\n",
    "        self._scan_and_deduplicate()\n",
    "\n",
    "    def _calculate_hash(self, filepath: str, block_size: int = 65536) -> str:\n",
    "        \"\"\"\n",
    "        Calculates the SHA256 hash of a file's content.\n",
    "        \"\"\"\n",
    "        sha256 = hashlib.sha256()\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                while chunk := f.read(block_size):\n",
    "                    sha256.update(chunk)\n",
    "            return sha256.hexdigest()\n",
    "        except (IOError, OSError) as e:\n",
    "            print(f\"Warning: Could not read file for hashing: {filepath}. Skipping. Error: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _scan_and_deduplicate(self):\n",
    "        \"\"\"\n",
    "        Walks the root directory, finds all unique images, and\n",
    "        populates self.labels with the default 'unknown' label.\n",
    "        \"\"\"\n",
    "        print(f\"Scanning directory: {self.root_dir}...\")\n",
    "        image_hashes: set[str] = set()\n",
    "        total_files = 0\n",
    "        duplicates_skipped = 0\n",
    "\n",
    "        for root, _, files in os.walk(self.root_dir):\n",
    "            for file in files:\n",
    "                if not file.lower().endswith(self.IMAGE_EXTENSIONS):\n",
    "                    continue\n",
    "\n",
    "                total_files += 1\n",
    "                full_path = os.path.join(root, file)\n",
    "                file_hash = self._calculate_hash(full_path)\n",
    "\n",
    "                if not file_hash:\n",
    "                    continue\n",
    "\n",
    "                if file_hash not in image_hashes:\n",
    "                    image_hashes.add(file_hash)\n",
    "                    # All images start as 'unknown'\n",
    "                    self.labels[full_path] = \"unknown\"\n",
    "                else:\n",
    "                    duplicates_skipped += 1\n",
    "\n",
    "        print(\"--- Scan Complete ---\")\n",
    "        print(f\"Total image files found: {total_files}\")\n",
    "        print(f\"Duplicate images skipped: {duplicates_skipped}\")\n",
    "        print(f\"Total unique images to process: {len(self.labels)}\")\n",
    "        if not self.labels:\n",
    "            print(\"Warning: No valid, unique images were found.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of unique images to be processed.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __iter__(self) -> Generator[Dict[str, str], None, None]:\n",
    "        \"\"\"\n",
    "        Yields batches of images as dictionaries {image_path: label}.\n",
    "        \"\"\"\n",
    "        # Get a static list of paths to iterate over\n",
    "        all_paths = list(self.labels.keys())\n",
    "        \n",
    "        for i in range(0, len(all_paths), self.batch_size):\n",
    "            batch_paths = all_paths[i : i + self.batch_size]\n",
    "            \n",
    "            # Create the batch dict\n",
    "            batch_data = {path: self.labels[path] for path in batch_paths}\n",
    "            \n",
    "            if batch_data:\n",
    "                yield batch_data\n",
    "\n",
    "\n",
    "class ImageClassifier:\n",
    "    \"\"\"\n",
    "    Uses a \"waterfall\" method to classify images from a dataloader\n",
    "    using multiple, chained AI models.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader: ImageDataloader, output_dir: str = \"output\"):\n",
    "        self.dataloader = dataloader\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # 1. Determine the device\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.pipeline_device = 0 if self.device == torch.device('cuda') else -1\n",
    "        print(f\"Using device: {self.device} (Pipeline device: {self.pipeline_device})\")\n",
    "        \n",
    "        self.output_paths = {\n",
    "            \"people\": os.path.join(output_dir, \"people\"),\n",
    "            \"view\": os.path.join(output_dir, \"view\"),\n",
    "            \"unknown\": os.path.join(output_dir, \"unknown\")\n",
    "        }\n",
    "        self._create_output_dirs()\n",
    "        \n",
    "        # --- Load Models in __init__ ---\n",
    "        print(\"Loading models...\")\n",
    "        \n",
    "        # Stage 1: Face Detector \n",
    "        self.retinaface_model = self.load_retinaface_model()\n",
    "        self.detr_pipeline = self.load_detr_pipeline()\n",
    "\n",
    "        # Stage 2: View Detector \n",
    "        self.clip_pipeline = self.load_clip_pipeline()\n",
    "\n",
    "        print(\"Model loading complete.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _create_output_dirs(self):\n",
    "        \"\"\"Creates the output directories if they don't exist.\"\"\"\n",
    "        print(f\"Ensuring output directories exist at: {self.output_dir}\")\n",
    "        for path in self.output_paths.values():\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    def _move_file(self, image_path: str, new_label: str):\n",
    "        \"\"\"Moves a file to its new classified directory.\"\"\"\n",
    "        if new_label not in self.output_paths:\n",
    "            print(f\"Warning: Unknown label '{new_label}'. Cannot move file.\")\n",
    "            return\n",
    "\n",
    "        target_dir = self.output_paths[new_label]\n",
    "        filename = os.path.basename(image_path)\n",
    "        target_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        i = 1\n",
    "        while os.path.exists(target_path):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            target_path = os.path.join(target_dir, f\"{name}_{i}{ext}\")\n",
    "            i += 1\n",
    "            \n",
    "        try:\n",
    "            shutil.move(image_path, target_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file {image_path} to {target_path}. Error: {e}\")\n",
    "\n",
    "    def _display_batch(self, batch_data: Dict[str, str], show_image: bool):\n",
    "        for key in batch_data:\n",
    "            print(key, batch_data[key])\n",
    "            if show_image:\n",
    "                plt.imshow(Image.open(key).convert('RGB'))\n",
    "                plt.show()\n",
    "\n",
    "    def classify_images(self):\n",
    "        \"\"\"\n",
    "        The main classification loop (orchestrator).\n",
    "        Iterates through all batches and applies the waterfall logic.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Starting Image Classification Waterfall ---\")\n",
    "        total_batches = (len(self.dataloader) + self.dataloader.batch_size - 1) // self.dataloader.batch_size\n",
    "        \n",
    "        for i, initial_batch in enumerate(self.dataloader):\n",
    "            print(f\"\\nProcessing Batch {i+1} / {total_batches} (Size: {len(initial_batch)})...\")\n",
    "            \n",
    "            remaining_batch = initial_batch.copy()\n",
    "\n",
    "            # --- STAGE 1: Detect faces ---\n",
    "            if self.retinaface_model:\n",
    "                remaining_batch = self.detect_human_detr_pipeline(remaining_batch, self.retinaface_model)\n",
    "            \n",
    "            # --- STAGE 1: Detect people ---\n",
    "            if self.retinaface_model:\n",
    "                remaining_batch = self.detect_with_RetinaFace(remaining_batch, self.retinaface_model)\n",
    "\n",
    "            # --- STAGE 2: View Models ---\n",
    "            if self.clip_pipeline:\n",
    "                remaining_batch = self.detect_view_clip_pipeline(\n",
    "                    remaining_batch, self.clip_pipeline,\n",
    "                    target_label=\"view\",\n",
    "                    prompts=[\"a photo of a landscape\", \"a beautiful view\", \"a flower\", \"a photo of food\", \"a city skyline\", \"a beach\", \"mountains\", \"a forest\"]\n",
    "                )\n",
    "\n",
    "            self._display_batch(remaining_batch, True)\n",
    "            \n",
    "                \n",
    "            print(f\"Batch {i+1} complete.\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n--- Image Classification Finished ---\")\n",
    "\n",
    "    # --- Specific Model Classification Methods ---\n",
    "    # --- Specific retinaface Model ---\n",
    "    def load_retinaface_model(self):\n",
    "        try:\n",
    "            app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "            app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "            print(\"Loaded: retinaface\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load retinaface. {e}\")\n",
    "            app = None\n",
    "        return app\n",
    "    \n",
    "\n",
    "    def detect_with_RetinaFace(self, batch_data, model):\n",
    "        \"\"\"\n",
    "        batch_data: dict {image_path: label}\n",
    "        model: RetinaFace model (insightface FaceAnalysis)\n",
    "\n",
    "        Processes only images labeled 'unknown'.\n",
    "        Returns updated batch_data with detections.\n",
    "        \"\"\"\n",
    "        updated_data = batch_data.copy()\n",
    "\n",
    "        # 1️⃣ Filter for unknown images\n",
    "        unknown_items = [(path, label) for path, label in batch_data.items() if label == \"unknown\"]\n",
    "        if not unknown_items:\n",
    "            return updated_data\n",
    "        \n",
    "        print(f\"\\nProcessing all {len(unknown_items)} 'unknown' images using the RetinaFace model...\")\n",
    "\n",
    "        image_paths = [p for p, _ in unknown_items]\n",
    "\n",
    "        # 2️⃣ Load all images once\n",
    "        loaded_images = {}\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_bgr = np.array(img)[:, :, ::-1]  # RGB → BGR\n",
    "                loaded_images[img_path] = img_bgr\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error reading {img_path}: {e}\")\n",
    "                updated_data[img_path] = \"invalid\"\n",
    "\n",
    "        # 3️⃣ Run inference per image (insightface doesn't support batch)\n",
    "        for img_path, img_bgr in loaded_images.items():\n",
    "            faces = model.get(img_bgr)  # must be called one by one\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                updated_data[img_path] = \"people\"\n",
    "\n",
    "        return updated_data\n",
    "\n",
    "    # --- Specific detr Model ---\n",
    "    def load_detr_pipeline(self):\n",
    "        try:\n",
    "            model = \"facebook/detr-resnet-50\"\n",
    "            detr_pipeline = pipeline(\"object-detection\", model=model, device=self.pipeline_device)\n",
    "            print(\"Loaded: facebook/detr-resnet-50\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load DETR. {e}\")\n",
    "            detr_pipeline = None\n",
    "        return detr_pipeline\n",
    "\n",
    "    def detect_human_detr_pipeline(self, batch_data: Dict[str, str], detr_pipeline: Any) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Detects humans ('person' label) in ALL images labeled 'unknown' using the \n",
    "        Hugging Face pipeline in a single batch operation and updates the labels.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            detr_pipeline (transformers.Pipeline): The loaded DETR object detection pipeline.\n",
    "            confidence_threshold (float): Minimum confidence for a detection to be considered.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        # DETR is trained on COCO, where the label for a human is 'person'\n",
    "        PERSON_LABEL = 'person' \n",
    "        confidence_threshold = 0.9\n",
    "\n",
    "        if detr_pipeline is None:\n",
    "            print(\"ERROR: Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        print(f\"\\nProcessing all {len(unknown_paths)} 'unknown' images using the detr pipeline...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # The pipeline handles moving data to the device defined during load.\n",
    "        # We pass the list of PIL images directly.\n",
    "        try:\n",
    "            # The result is a list of lists: [[det1, det2, ...], [det1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = detr_pipeline(batch_images)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 3. Post-process the results\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            is_human_detected = False\n",
    "            \n",
    "            # image_results is a list of dictionaries (one for each detection)\n",
    "            for detection in image_results:\n",
    "                # The pipeline provides the score and the label (e.g., 'person')\n",
    "                if detection['score'] >= confidence_threshold and detection['label'] == PERSON_LABEL:\n",
    "                    is_human_detected = True\n",
    "                    # print(f\"✅ Detected {PERSON_LABEL} in: {image_path} with score {detection['score']:.2f}\")\n",
    "                    break # Found a person, no need to check other detections for this image\n",
    "\n",
    "            if is_human_detected:\n",
    "                batch_data[image_path] = 'people'\n",
    "\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using the pipeline.\")\n",
    "        return batch_data\n",
    "\n",
    "    # --- Specific clip Model ---\n",
    "    def load_clip_pipeline(self):\n",
    "        \"\"\"\n",
    "        Loads the CLIP zero-shot classification pipeline.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            clip_pipeline = pipeline(\n",
    "                \"zero-shot-image-classification\",\n",
    "                model=\"openai/clip-vit-large-patch14\",\n",
    "                device=self.pipeline_device  \n",
    "            )\n",
    "            print(\"Loaded: clip-vit-large-patch14\")\n",
    "            return clip_pipeline  # <-- FIX: You must return the loaded pipeline\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load CLIP. {e}\")\n",
    "            return None # Return None on failure\n",
    "\n",
    "    def detect_view_clip_pipeline(self, batch_data: Dict[str, str], clip_pipeline: Any, target_label: str, prompts: List[str], confidence_threshold: float = 0.80) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classifies images labeled 'unknown' using the CLIP pipeline and a list of prompts.\n",
    "        \n",
    "        If the top-scoring prompt meets the confidence threshold, the image label\n",
    "        is updated to the single `target_label`.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            clip_pipeline (transformers.Pipeline): The loaded CLIP pipeline.\n",
    "            target_label (str): The new label to assign if a match is found (e.g., 'view').\n",
    "            prompts (list): A list of candidate labels to check against (e.g., \"a flower\").\n",
    "            confidence_threshold (float): Minimum confidence for a classification.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        if clip_pipeline is None:\n",
    "            print(\"ERROR: CLIP Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found for CLIP processing. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        print(f\"\\nProcessing {len(unknown_paths)} 'unknown' images using CLIP with {len(prompts)} prompts...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded for CLIP. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # We pass the list of PIL images and the candidate labels\n",
    "        try:\n",
    "            # The result is a list of lists: [[class1, class2, ...], [class1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = clip_pipeline(\n",
    "                batch_images, \n",
    "                candidate_labels=prompts\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during CLIP pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 3. Post-process the results\n",
    "        update_count = 0\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            \n",
    "            # The pipeline returns all prompts, sorted by score.\n",
    "            # We only care about the top-scoring one.\n",
    "            top_detection = image_results[0]\n",
    "            \n",
    "            # Check if the top score meets our threshold.\n",
    "            # Since the pipeline only returns labels from our `prompts` list,\n",
    "            # we know the label is one we are looking for.\n",
    "            if top_detection['score'] >= confidence_threshold:\n",
    "                # print(f\"✅ Classified {image_path} as '{top_detection['label']}' (score: {top_detection['score']:.2f}). Setting label to '{target_label}'.\")\n",
    "                \n",
    "                # Update the label to the generic target_label\n",
    "                batch_data[image_path] = target_label\n",
    "                update_count += 1\n",
    "            else:\n",
    "                # The top score was too low, so we \"leave it\" (it remains 'unknown')\n",
    "                pass\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using CLIP. Updated {update_count} labels to '{target_label}'.\")\n",
    "        return batch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 1. Load RetinaFace model\n",
    "# -------------------------------------------------------\n",
    "def load_retinaface_model():\n",
    "    app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "    return app\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 2. Detect faces using Pillow images\n",
    "# -------------------------------------------------------\n",
    "def detect_with_RetinaFace(batch_data, model):\n",
    "    \"\"\"\n",
    "    batch_data: dict {image_path: label}\n",
    "    model: RetinaFace model (insightface FaceAnalysis)\n",
    "\n",
    "    Processes only images labeled 'unknown'.\n",
    "    Returns updated batch_data with detections.\n",
    "    \"\"\"\n",
    "    updated_data = batch_data.copy()\n",
    "\n",
    "    # 1️⃣ Filter for unknown images\n",
    "    unknown_items = [(path, label) for path, label in batch_data.items() if label == \"unknown\"]\n",
    "    if not unknown_items:\n",
    "        return updated_data\n",
    "\n",
    "    image_paths = [p for p, _ in unknown_items]\n",
    "\n",
    "    # 2️⃣ Load all images once\n",
    "    loaded_images = {}\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_bgr = np.array(img)[:, :, ::-1]  # RGB → BGR\n",
    "            loaded_images[img_path] = img_bgr\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error reading {img_path}: {e}\")\n",
    "            updated_data[img_path] = \"invalid\"\n",
    "\n",
    "    # 3️⃣ Run inference per image (insightface doesn't support batch)\n",
    "    for img_path, img_bgr in loaded_images.items():\n",
    "        faces = model.get(img_bgr)  # must be called one by one\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            updated_data[img_path] = \"people\"\n",
    "\n",
    "    return updated_data\n",
    "\n",
    "test_dir = r\"D:\\images\\HockingHills\"\n",
    "output = r\"D:\\images\\output\"\n",
    "\n",
    "# 1. Instantiate the Dataloader\n",
    "# Using a small batch size for the example\n",
    "dataloader = ImageDataloader(root_dir=test_dir, batch_size=32)\n",
    "\n",
    "retinaface_model = load_retinaface_model()\n",
    "\n",
    "for batch in dataloader:\n",
    "    result = detect_with_RetinaFace(batch, retinaface_model)\n",
    "    print(result)\n",
    "    break\n",
    "\n",
    "for key in batch:\n",
    "    print(key, batch[key], result[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
