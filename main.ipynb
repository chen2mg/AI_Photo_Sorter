{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEIC/HEIF support enabled.\n",
      "FaceAnalysis support enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import shutil\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Generator, Any\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter  \n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "# --- HEIC/HEIF Support ---\n",
    "# This is required to make PIL.Image.open() support HEIC/HEIF formats.\n",
    "# You must install this library: pip install pillow-heif\n",
    "try:\n",
    "    import pillow_heif\n",
    "    pillow_heif.register_heif_opener()\n",
    "    print(\"HEIC/HEIF support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: 'pillow-heif' not installed. HEIC/HEIF files will be skipped.\")\n",
    "    print(\"Install with: pip install pillow-heif\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "try:\n",
    "    from insightface.app import FaceAnalysis\n",
    "    print(\"FaceAnalysis support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: FaceAnalysis not installed.\")\n",
    "    print(\"pip install insightface\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "# --- Hugging Face transformers ---\n",
    "# You must install this library: pip install transformers torch\n",
    "try:\n",
    "    from transformers import pipeline, Pipeline\n",
    "    from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"CRITICAL: 'transformers' or 'torch' not found.\")\n",
    "    print(\"Please install them to run this script: pip install transformers torch\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "class ImageDataloader:\n",
    "    \"\"\"\n",
    "    Scans a directory for unique images and provides batches for processing.\n",
    "\n",
    "    This class is implemented as a Python generator. It does not\n",
    "    inherit from torch.utils.data.DataLoader, as our use case\n",
    "    requires a simple, stateful iterator.\n",
    "    \"\"\"\n",
    "    IMAGE_EXTENSIONS: tuple = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "\n",
    "    def __init__(self, root_dir: str, batch_size: int = 32):\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"Root directory not found: {root_dir}\")\n",
    "        if batch_size <= 0:\n",
    "            raise ValueError(\"Batch size must be greater than 0\")\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.labels will hold the \"working state\" of all images\n",
    "        # {image_path: \"unknown\"}\n",
    "        self.labels: Dict[str, str] = {}\n",
    "        self._scan_and_deduplicate()\n",
    "\n",
    "    def _calculate_hash(self, filepath: str, block_size: int = 65536) -> str:\n",
    "        \"\"\"\n",
    "        Calculates the SHA256 hash of a file's content.\n",
    "        \"\"\"\n",
    "        sha256 = hashlib.sha256()\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                while chunk := f.read(block_size):\n",
    "                    sha256.update(chunk)\n",
    "            return sha256.hexdigest()\n",
    "        except (IOError, OSError) as e:\n",
    "            print(f\"Warning: Could not read file for hashing: {filepath}. Skipping. Error: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _scan_and_deduplicate(self):\n",
    "        \"\"\"\n",
    "        Walks the root directory, finds all unique images, and\n",
    "        populates self.labels with the default 'unknown' label.\n",
    "        \"\"\"\n",
    "        print(f\"Scanning directory: {self.root_dir}...\")\n",
    "        image_hashes: set[str] = set()\n",
    "        total_files = 0\n",
    "        duplicates_skipped = 0\n",
    "\n",
    "        for root, _, files in os.walk(self.root_dir):\n",
    "            for file in files:\n",
    "                if not file.lower().endswith(self.IMAGE_EXTENSIONS):\n",
    "                    continue\n",
    "\n",
    "                total_files += 1\n",
    "                full_path = os.path.join(root, file)\n",
    "                file_hash = self._calculate_hash(full_path)\n",
    "\n",
    "                if not file_hash:\n",
    "                    continue\n",
    "\n",
    "                if file_hash not in image_hashes:\n",
    "                    image_hashes.add(file_hash)\n",
    "                    # All images start as 'unknown'\n",
    "                    self.labels[full_path] = \"unknown\"\n",
    "                else:\n",
    "                    duplicates_skipped += 1\n",
    "\n",
    "        print(\"--- Scan Complete ---\")\n",
    "        print(f\"Total image files found: {total_files}\")\n",
    "        print(f\"Duplicate images skipped: {duplicates_skipped}\")\n",
    "        print(f\"Total unique images to process: {len(self.labels)}\")\n",
    "        if not self.labels:\n",
    "            print(\"Warning: No valid, unique images were found.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of unique images to be processed.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __iter__(self) -> Generator[Dict[str, str], None, None]:\n",
    "        \"\"\"\n",
    "        Yields batches of images as dictionaries {image_path: label}.\n",
    "        \"\"\"\n",
    "        # Get a static list of paths to iterate over\n",
    "        all_paths = list(self.labels.keys())\n",
    "        \n",
    "        for i in range(0, len(all_paths), self.batch_size):\n",
    "            batch_paths = all_paths[i : i + self.batch_size]\n",
    "            \n",
    "            # Create the batch dict\n",
    "            batch_data = {path: self.labels[path] for path in batch_paths}\n",
    "            \n",
    "            if batch_data:\n",
    "                yield batch_data\n",
    "\n",
    "\n",
    "class ImageClassifier:\n",
    "    \"\"\"\n",
    "    Uses a \"waterfall\" method to classify images from a dataloader\n",
    "    using multiple, chained AI models.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader: ImageDataloader, output_dir: str = \"output\"):\n",
    "        self.dataloader = dataloader\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # this variable save final prediction\n",
    "        self.processed_images = {}\n",
    "\n",
    "        # 1. Determine the device\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.pipeline_device = 0 if self.device == torch.device('cuda') else -1\n",
    "        print(f\"Using device: {self.device} (Pipeline device: {self.pipeline_device})\")\n",
    "        \n",
    "        self.output_paths = {\n",
    "            \"people\": os.path.join(output_dir, \"people\"),\n",
    "            \"view\": os.path.join(output_dir, \"view\"),\n",
    "            \"screen_shot\": os.path.join(output_dir, \"screen_shot\"),\n",
    "            \"unknown\": os.path.join(output_dir, \"unknown\")\n",
    "        }\n",
    "        self._create_output_dirs()\n",
    "        \n",
    "        # --- Load Models in __init__ ---\n",
    "        print(\"Loading models...\")\n",
    "        \n",
    "        # Stage 1: Face Detector \n",
    "        self.retinaface_model = self.load_retinaface_model()\n",
    "        self.detr_pipeline = self.load_detr_pipeline()\n",
    "\n",
    "        # Stage 2: View Detector \n",
    "        self.clip_pipeline = self.load_clip_pipeline()\n",
    "\n",
    "        print(\"Model loading complete.\")\n",
    "\n",
    "\n",
    "    def _create_output_dirs(self):\n",
    "        \"\"\"Creates the output directories if they don't exist.\"\"\"\n",
    "        print(f\"Ensuring output directories exist at: {self.output_dir}\")\n",
    "        for path in self.output_paths.values():\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "    def _move_file(self, batch_data: Dict[str, str], action='move'):\n",
    "        \"\"\"\n",
    "        batch_data: dict {image_path: label}\n",
    "\n",
    "        Moves a batch of image files to their classified directories.\n",
    "        \"\"\"\n",
    "        assert action in ['move', 'copy']\n",
    "        # Iterate over each image path and its assigned label in the dictionary\n",
    "        for image_path, new_label in batch_data.items():\n",
    "            try:\n",
    "                # 1. Get destination directory. Default to 'unknown' if label is invalid.\n",
    "                dest_dir = self.output_paths.get(new_label, self.output_paths[\"unknown\"])\n",
    "                \n",
    "                # 2. Get the base filename from the full path\n",
    "                filename = os.path.basename(image_path)\n",
    "                \n",
    "                # 3. Create the full destination path\n",
    "                dest_path = os.path.join(dest_dir, filename)\n",
    "                \n",
    "\n",
    "                # 5. Move the file\n",
    "                if action=='move':\n",
    "                    shutil.move(image_path, dest_path)\n",
    "                else:\n",
    "                    shutil.copy2(image_path, dest_path)\n",
    "\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found, cannot move: {image_path}\")\n",
    "            except PermissionError:\n",
    "                print(f\"Permission denied, cannot move: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to move {image_path}: {e}\")\n",
    "\n",
    "\n",
    "    def _display_batch(self, batch_data: Dict[str, str], show_image=False):\n",
    "        \"\"\"\n",
    "        Displays a summary of batch data (category counts) and optionally\n",
    "        renders each image with its category as the title.\n",
    "\n",
    "        Args:\n",
    "            batch_data (Dict[str, str]): Dictionary where keys are file paths \n",
    "                                        and values are the categories/labels.\n",
    "            show_image (bool): A flag to control whether to display images.\n",
    "        \"\"\"\n",
    "        # --- Batch Summary Section ---\n",
    "        \n",
    "        # Use collections.Counter to efficiently count the occurrences of each \n",
    "        # unique value (category) in the batch_data dictionary.\n",
    "        value_counts = Counter(batch_data.values())\n",
    "        \n",
    "        print(\"Counts for each unique value in this batch:\")\n",
    "        \n",
    "        # Loop through the resulting Counter object (value_counts.items())\n",
    "        for value, count in value_counts.items():\n",
    "            # Prints each unique value and its total count\n",
    "            print(f\"  Image category '{value}': {count} time(s)\")\n",
    "            \n",
    "        print(\"-----------------------------------------\")\n",
    "        \n",
    "        # --- Image Display Section ---\n",
    "        \n",
    "        # This entire block is conditional. It only runs if show_image=True\n",
    "        if show_image:\n",
    "            for key in batch_data:\n",
    "                # Print the file path being processed\n",
    "                print(key)\n",
    "                plt.title(batch_data[key])\n",
    "                plt.imshow(Image.open(key).convert('RGB'))\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "    def classify_images(self):\n",
    "        \"\"\"\n",
    "        The main classification loop (orchestrator).\n",
    "        Iterates through all batches and applies the waterfall logic.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Starting Image Classification Waterfall ---\")\n",
    "        total_batches = (len(self.dataloader) + self.dataloader.batch_size - 1) // self.dataloader.batch_size\n",
    "        \n",
    "        for i, initial_batch in enumerate(self.dataloader):\n",
    "            print(f\"\\nProcessing Batch {i+1} / {total_batches} (Size: {len(initial_batch)})...\")\n",
    "            \n",
    "            remaining_batch = initial_batch.copy()\n",
    "            # --- STAGE 0: Detect screen shot ---\n",
    "            remaining_batch = self.check_screen_shot(remaining_batch)\n",
    "\n",
    "            # --- STAGE 1: Detect faces ---\n",
    "            if self.retinaface_model:\n",
    "                remaining_batch = self.detect_human_detr_pipeline(remaining_batch, self.detr_pipeline)\n",
    "            \n",
    "            # --- STAGE 1: Detect people ---\n",
    "            if self.retinaface_model:\n",
    "                remaining_batch = self.detect_with_RetinaFace(remaining_batch, self.retinaface_model)\n",
    "\n",
    "            # --- STAGE 2: View Models ---\n",
    "            if self.clip_pipeline:\n",
    "                remaining_batch = self.detect_view_clip_pipeline(\n",
    "                    remaining_batch, self.clip_pipeline,\n",
    "                    target_label=\"view\",\n",
    "                    prompts=[\"a photo of a landscape\", \"a beautiful view\", \"a flower\", \"a photo of food\", \"a city skyline\", \"a beach\", \"mountains\", \"a forest\"]\n",
    "                )\n",
    "\n",
    "\n",
    "            self._move_file(remaining_batch, 'copy')\n",
    "            self.processed_images |=remaining_batch\n",
    "            print(f\"Batch {i+1} complete.\")\n",
    "        \n",
    "        self._display_batch(self.processed_images)\n",
    "\n",
    "        print(\"\\n--- Image Classification Finished ---\")\n",
    "\n",
    "    # --- Specific Model Classification Methods ---\n",
    "    # --- Specific retinaface Model ---\n",
    "    def load_retinaface_model(self):\n",
    "        # try:\n",
    "        #     app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "        #     app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "        #     print(\"Loaded: retinaface\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"CRITICAL: Failed to load retinaface. {e}\")\n",
    "        #     app = None\n",
    "\n",
    "        app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "        app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "        return app\n",
    "    \n",
    "    def detect_with_RetinaFace(self, batch_data, model, target_label='people'):\n",
    "        \"\"\"\n",
    "        batch_data: dict {image_path: label}\n",
    "        model: RetinaFace model (insightface FaceAnalysis)\n",
    "\n",
    "        Processes only images labeled 'unknown'.\n",
    "        Returns updated batch_data with detections.\n",
    "        \"\"\"\n",
    "        updated_data = batch_data.copy()\n",
    "\n",
    "        # 1️⃣ Filter for unknown images\n",
    "        unknown_items = [(path, label) for path, label in batch_data.items() if label == \"unknown\"]\n",
    "        if not unknown_items:\n",
    "            return updated_data\n",
    "        \n",
    "        #print(f\"\\nProcessing {len(unknown_items)} 'unknown' images using the RetinaFace model...\")\n",
    "\n",
    "        image_paths = [p for p, _ in unknown_items]\n",
    "\n",
    "        # 2️⃣ Load all images once\n",
    "        loaded_images = {}\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_bgr = np.array(img)[:, :, ::-1]  # RGB → BGR\n",
    "                loaded_images[img_path] = img_bgr\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error reading {img_path}: {e}\")\n",
    "                updated_data[img_path] = \"invalid\"\n",
    "\n",
    "        update_count=0\n",
    "        # 3️⃣ Run inference per image (insightface doesn't support batch)\n",
    "        for img_path, img_bgr in loaded_images.items():\n",
    "            faces = model.get(img_bgr)  # must be called one by one\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                updated_data[img_path] = target_label\n",
    "                update_count+=1\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(unknown_items)} images using detr. Updated {update_count} labels to '{target_label}'.\")\n",
    "        return updated_data\n",
    "\n",
    "    # --- Specific detr Model ---\n",
    "    def load_detr_pipeline(self):\n",
    "        try:\n",
    "            model = \"facebook/detr-resnet-50\"\n",
    "            detr_pipeline = pipeline(\"object-detection\", model=model, device=self.pipeline_device)\n",
    "            print(\"Loaded: facebook/detr-resnet-50\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load DETR. {e}\")\n",
    "            detr_pipeline = None\n",
    "        return detr_pipeline\n",
    "\n",
    "    def detect_human_detr_pipeline(self, batch_data: Dict[str, str], detr_pipeline: Any, target_label='people') -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Detects humans ('person' label) in ALL images labeled 'unknown' using the \n",
    "        Hugging Face pipeline in a single batch operation and updates the labels.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            detr_pipeline (transformers.Pipeline): The loaded DETR object detection pipeline.\n",
    "            confidence_threshold (float): Minimum confidence for a detection to be considered.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        # DETR is trained on COCO, where the label for a human is 'person'\n",
    "        PERSON_LABEL = 'person' \n",
    "        confidence_threshold = 0.9\n",
    "\n",
    "        if detr_pipeline is None:\n",
    "            print(\"ERROR: Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        # print(f\"\\nProcessing all {len(unknown_paths)} 'unknown' images using the detr pipeline...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # The pipeline handles moving data to the device defined during load.\n",
    "        # We pass the list of PIL images directly.\n",
    "        try:\n",
    "            # The result is a list of lists: [[det1, det2, ...], [det1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = detr_pipeline(batch_images)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        update_count = 0\n",
    "        # 3. Post-process the results\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            is_human_detected = False\n",
    "            \n",
    "            # image_results is a list of dictionaries (one for each detection)\n",
    "            for detection in image_results:\n",
    "                # The pipeline provides the score and the label (e.g., 'person')\n",
    "                if detection['score'] >= confidence_threshold and detection['label'] == PERSON_LABEL:\n",
    "                    is_human_detected = True\n",
    "                    # print(f\"✅ Detected {PERSON_LABEL} in: {image_path} with score {detection['score']:.2f}\")\n",
    "                    break # Found a person, no need to check other detections for this image\n",
    "\n",
    "            if is_human_detected:\n",
    "                batch_data[image_path] = target_label\n",
    "                update_count+=1\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using detr. Updated {update_count} labels to '{target_label}'.\")\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "    # --- Specific clip Model ---\n",
    "    def load_clip_pipeline(self):\n",
    "        \"\"\"\n",
    "        Loads the CLIP zero-shot classification pipeline.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            clip_pipeline = pipeline(\n",
    "                \"zero-shot-image-classification\",\n",
    "                model=\"openai/clip-vit-large-patch14\",\n",
    "                device=self.pipeline_device  \n",
    "            )\n",
    "            print(\"Loaded: clip-vit-large-patch14\")\n",
    "            return clip_pipeline  # <-- FIX: You must return the loaded pipeline\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load CLIP. {e}\")\n",
    "            return None # Return None on failure\n",
    "\n",
    "    def detect_view_clip_pipeline(self, batch_data: Dict[str, str], clip_pipeline: Any, target_label: str, prompts: List[str], confidence_threshold: float = 0.80) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classifies images labeled 'unknown' using the CLIP pipeline and a list of prompts.\n",
    "        \n",
    "        If the top-scoring prompt meets the confidence threshold, the image label\n",
    "        is updated to the single `target_label`.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            clip_pipeline (transformers.Pipeline): The loaded CLIP pipeline.\n",
    "            target_label (str): The new label to assign if a match is found (e.g., 'view').\n",
    "            prompts (list): A list of candidate labels to check against (e.g., \"a flower\").\n",
    "            confidence_threshold (float): Minimum confidence for a classification.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        if clip_pipeline is None:\n",
    "            print(\"ERROR: CLIP Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found for CLIP processing. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        # print(f\"\\nProcessing {len(unknown_paths)} 'unknown' images using CLIP with {len(prompts)} prompts...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded for CLIP. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # We pass the list of PIL images and the candidate labels\n",
    "        try:\n",
    "            # The result is a list of lists: [[class1, class2, ...], [class1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = clip_pipeline(\n",
    "                batch_images, \n",
    "                candidate_labels=prompts\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during CLIP pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 3. Post-process the results\n",
    "        update_count = 0\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            \n",
    "            # The pipeline returns all prompts, sorted by score.\n",
    "            # We only care about the top-scoring one.\n",
    "            top_detection = image_results[0]\n",
    "            \n",
    "            # Check if the top score meets our threshold.\n",
    "            # Since the pipeline only returns labels from our `prompts` list,\n",
    "            # we know the label is one we are looking for.\n",
    "            if top_detection['score'] >= confidence_threshold:\n",
    "                # print(f\"✅ Classified {image_path} as '{top_detection['label']}' (score: {top_detection['score']:.2f}). Setting label to '{target_label}'.\")\n",
    "                \n",
    "                # Update the label to the generic target_label\n",
    "                batch_data[image_path] = target_label\n",
    "                update_count += 1\n",
    "            else:\n",
    "                # The top score was too low, so we \"leave it\" (it remains 'unknown')\n",
    "                pass\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using CLIP. Updated {update_count} labels to '{target_label}'.\")\n",
    "        return batch_data\n",
    "\n",
    "    # --- Specific screen shot Model ---\n",
    "    def check_screen_shot(self, batch_data: Dict[str, str], target_label='screen_shot') -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classifies images labeled 'unknown' using a two-stage heuristic method.\n",
    "        \n",
    "        1. Disqualifies images with camera-specific EXIF data.\n",
    "        2. Qualifies images that lack camera EXIF and match known iPhone screen resolutions.\n",
    "        \n",
    "        Updated the image label in batch_data to `target_label` or 'photo'.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            target_label (str): The new label to assign if a match is found (e.g., 'screen_shot').\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- Start of self-contained logic ---\n",
    "        \n",
    "        # 1. Define necessary constants and lookups\n",
    "        \n",
    "        # We need to get the string names for the numeric EXIF tag IDs\n",
    "        # This creates a lookup like {271: 'Make', 272: 'Model', ...}\n",
    "        try:\n",
    "            TAGS_LOOKUP = {v: k for k, v in ExifTags.TAGS.items()}\n",
    "        except AttributeError:\n",
    "            # Fallback in case ExifTags.TAGS isn't available (though it should be)\n",
    "            TAGS_LOOKUP = {}\n",
    "\n",
    "        # EXIF tags that strongly indicate a photo was taken by a camera\n",
    "        CAMERA_EXIF_TAGS = {\n",
    "            \"Make\", \"Model\", \"ExposureTime\", \"FNumber\", \n",
    "            \"ISOSpeedRatings\", \"DateTimeOriginal\", \"LensModel\", \"GPSInfo\"\n",
    "        }\n",
    "        \n",
    "        # A list of (width, height) tuples for known iPhone physical resolutions\n",
    "        _IPHONE_RESOLUTIONS_BASE = [\n",
    "            (750, 1334),   # iPhone 6 / 6S / 7 / 8 / SE (2nd/3rd gen)\n",
    "            (1080, 1920),  # iPhone 6+ / 6S+ / 7+ / 8+ (actual rendered resolution)\n",
    "            (640, 1136),   # iPhone SE (1st gen) / 5S\n",
    "            (1125, 2436),  # iPhone X / XS / 11 Pro (5.8″)\n",
    "            (828, 1792),   # iPhone XR / 11 (6.1″)\n",
    "            (1242, 2688),  # iPhone XS Max / 11 Pro Max (6.5″)\n",
    "            (1080, 2340),  # iPhone 12 mini / 13 mini (5.4″)\n",
    "            (1170, 2532),  # iPhone 12 / 12 Pro / 13 / 13 Pro / (14 6.1″) / (15 6.1″) — verify model variant\n",
    "            (1284, 2778),  # iPhone 12 Pro Max / 13 Pro Max / (14 Plus) / (15 Plus) — verify model variant\n",
    "            (1179, 2556),  # iPhone 14 Pro (6.1″) / iPhone 15 Pro (6.1″) — spec confirms 2556×1179. :contentReference[oaicite:18]{index=18}\n",
    "            (1206, 2622),  # iPhone 16 Pro (6.3″) / iPhone 17 (6.3″) — confirms 2622×1206. :contentReference[oaicite:19]{index=19}\n",
    "            (1320, 2868),  # iPhone 16 Pro Max / iPhone 17 Pro Max (6.9″) — spec confirm 2868×1320. :contentReference[oaicite:20]{index=20}\n",
    "        ]\n",
    "        \n",
    "        # Create the final set we'll check against\n",
    "        # Add both (W, H) and (H, W) to catch portrait/landscape\n",
    "        IPHONE_SCREEN_SIZES = set()\n",
    "        for w, h in _IPHONE_RESOLUTIONS_BASE:\n",
    "            IPHONE_SCREEN_SIZES.add((w, h))\n",
    "            IPHONE_SCREEN_SIZES.add((h, w))\n",
    "            \n",
    "        # --- End of self-contained logic ---\n",
    "        \n",
    "        update_count = 0\n",
    "        # Iterate over a static list of keys to safely modify the dictionary\n",
    "        for image_path in list(batch_data.keys()):\n",
    "            label = batch_data[image_path]\n",
    "            \n",
    "            # Only process images labeled 'unknown'\n",
    "            if label != 'unknown':\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    \n",
    "                    # --- Heuristic 1: Check for DISQUALIFYING camera EXIF data ---\n",
    "                    # We default to assuming it's not a photo until proven.\n",
    "                    is_photo = False\n",
    "                    \n",
    "                    # Suppress PIL.Image.DecompressionBombWarning if images are very large\n",
    "                    # This check is basic; for production, you'd set Image.MAX_IMAGE_PIXELS\n",
    "                    \n",
    "                    exif_data = img.getexif()\n",
    "                    if exif_data:\n",
    "                        for tag_id, value in exif_data.items():\n",
    "                            # Look up the tag name (e.g., 271 -> 'Make')\n",
    "                            tag_name = TAGS_LOOKUP.get(tag_id, tag_id)\n",
    "                            \n",
    "                            if tag_name in CAMERA_EXIF_TAGS:\n",
    "                                is_photo = True\n",
    "                                break\n",
    "                    \n",
    "                    if is_photo:\n",
    "                        # This is almost certainly a camera photo.\n",
    "                        # Re-label it and stop processing this image.\n",
    "                        batch_data[image_path] = 'photo'\n",
    "                        continue \n",
    "\n",
    "                    # --- Heuristic 2: Check for QUALIFYING screen dimensions ---\n",
    "                    # This code only runs if the image had NO EXIF data, \n",
    "                    # or had EXIF data but no camera-specific tags.\n",
    "                    dimensions = img.size  # (width, height)\n",
    "                    \n",
    "                    if dimensions in IPHONE_SCREEN_SIZES:\n",
    "                        # Matched a known resolution and wasn't a photo\n",
    "                        batch_data[image_path] = target_label\n",
    "                        update_count+=0\n",
    "                    # else:\n",
    "                        # It remains 'unknown' if it doesn't match\n",
    "            \n",
    "\n",
    "            except Image.DecompressionBombError:\n",
    "                print(f\"Warning: Image {image_path} is too large to process safely (DecompressionBomb). Labeling as 'error'.\")\n",
    "                batch_data[image_path] = 'processing_error'\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: Image file not found at {image_path}. Labeling as 'error'.\")\n",
    "                batch_data[image_path] = 'file_not_found'\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not process image {image_path}. Error: {e}\")\n",
    "                batch_data[image_path] = 'processing_error'\n",
    "        \n",
    "        print(f\"\\nSuccessfully processed {len(batch_data)} images using CLIP. Updated {update_count} labels to '{target_label}'.\")\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "\n",
    "    def place_hold(self, batch_data: Dict[str, str], target_label='screen_shot') -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classifies images labeled 'unknown' using the proposed method.\n",
    "        \n",
    "        Updated the image label in batch_data to `target_label`.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            target_label (str): The new label to assign if a match is found (e.g., 'screen_shot').\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72d7361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: D:\\images\\images...\n",
      "--- Scan Complete ---\n",
      "Total image files found: 8619\n",
      "Duplicate images skipped: 0\n",
      "Total unique images to process: 8619\n",
      "Using device: cuda (Pipeline device: 0)\n",
      "Ensuring output directories exist at: D:\\images\\output\n",
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: facebook/detr-resnet-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: clip-vit-large-patch14\n",
      "Model loading complete.\n",
      "\n",
      "--- Starting Image Classification Waterfall ---\n",
      "\n",
      "Processing Batch 1 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 1 complete.\n",
      "\n",
      "Processing Batch 2 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 2 complete.\n",
      "\n",
      "Processing Batch 3 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 3 complete.\n",
      "\n",
      "Processing Batch 4 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 4 complete.\n",
      "\n",
      "Processing Batch 5 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 5 complete.\n",
      "\n",
      "Processing Batch 6 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 6 complete.\n",
      "\n",
      "Processing Batch 7 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 31 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 31 images using detr. Updated 31 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 7 complete.\n",
      "\n",
      "Processing Batch 8 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 8 complete.\n",
      "\n",
      "Processing Batch 9 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 29 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 29 images using detr. Updated 26 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 3 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 3 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 9 complete.\n",
      "\n",
      "Processing Batch 10 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 10 complete.\n",
      "\n",
      "Processing Batch 11 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 11 complete.\n",
      "\n",
      "Processing Batch 12 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 12 complete.\n",
      "\n",
      "Processing Batch 13 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 13 complete.\n",
      "\n",
      "Processing Batch 14 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 14 complete.\n",
      "\n",
      "Processing Batch 15 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 15 complete.\n",
      "\n",
      "Processing Batch 16 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 16 complete.\n",
      "\n",
      "Processing Batch 17 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 17 complete.\n",
      "\n",
      "Processing Batch 18 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 18 complete.\n",
      "\n",
      "Processing Batch 19 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 29 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 3 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 19 complete.\n",
      "\n",
      "Processing Batch 20 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 31 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 31 images using detr. Updated 29 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 20 complete.\n",
      "\n",
      "Processing Batch 21 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 29 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 3 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 21 complete.\n",
      "\n",
      "Processing Batch 22 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 22 complete.\n",
      "\n",
      "Processing Batch 23 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 31 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 31 images using detr. Updated 27 labels to 'people'.\n",
      "\n",
      "Processing 4 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 4 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 3 images using CLIP. Updated 1 labels to 'view'.\n",
      "Batch 23 complete.\n",
      "\n",
      "Processing Batch 24 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 24 complete.\n",
      "\n",
      "Processing Batch 25 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 31 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 31 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 25 complete.\n",
      "\n",
      "Processing Batch 26 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 30 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 30 images using detr. Updated 29 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 1 labels to 'view'.\n",
      "Batch 26 complete.\n",
      "\n",
      "Processing Batch 27 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 23 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 23 images using detr. Updated 23 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 27 complete.\n",
      "\n",
      "Processing Batch 28 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 28 complete.\n",
      "\n",
      "Processing Batch 29 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 29 complete.\n",
      "\n",
      "Processing Batch 30 / 270 (Size: 32)...\n",
      "\n",
      "Successfully processed 32 images using CLIP. Updated 0 labels to 'screen_shot'.\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m classifier = ImageClassifier(dataloader=dataloader, output_dir=output)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAn error occurred during classification: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 276\u001b[39m, in \u001b[36mImageClassifier.classify_images\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# --- STAGE 1: Detect faces ---\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.retinaface_model:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     remaining_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetect_human_detr_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetr_pipeline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# --- STAGE 1: Detect people ---\u001b[39;00m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.retinaface_model:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 419\u001b[39m, in \u001b[36mImageClassifier.detect_human_detr_pipeline\u001b[39m\u001b[34m(self, batch_data, detr_pipeline, target_label)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# 2. Perform single batch inference\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# The pipeline handles moving data to the device defined during load.\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# We pass the list of PIL images directly.\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    418\u001b[39m     \u001b[38;5;66;03m# The result is a list of lists: [[det1, det2, ...], [det1, ...], ...]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     results: List[List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] = \u001b[43mdetr_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    421\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRUNTIME ERROR during pipeline execution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\pipelines\\object_detection.py:106\u001b[39m, in \u001b[36mObjectDetectionPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    105\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\pipelines\\base.py:1360\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1357\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1358\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1359\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m    124\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\pipelines\\object_detection.py:153\u001b[39m, in \u001b[36mObjectDetectionPipeline.postprocess\u001b[39m\u001b[34m(self, model_outputs, threshold)\u001b[39m\n\u001b[32m    150\u001b[39m     annotation = [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, vals)) \u001b[38;5;28;01mfor\u001b[39;00m vals \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(scores.tolist(), labels, boxes) \u001b[38;5;28;01mif\u001b[39;00m vals[\u001b[32m0\u001b[39m] > threshold]\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# This is a regular ForObjectDetectionModel\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     raw_annotations = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimage_processor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost_process_object_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     raw_annotation = raw_annotations[\u001b[32m0\u001b[39m]\n\u001b[32m    155\u001b[39m     scores = raw_annotation[\u001b[33m\"\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\models\\detr\\image_processing_detr.py:1803\u001b[39m, in \u001b[36mDetrImageProcessor.post_process_object_detection\u001b[39m\u001b[34m(self, outputs, threshold, target_sizes)\u001b[39m\n\u001b[32m   1800\u001b[39m scores, labels = prob[..., :-\u001b[32m1\u001b[39m].max(-\u001b[32m1\u001b[39m)\n\u001b[32m   1802\u001b[39m \u001b[38;5;66;03m# Convert to [x0, y0, x1, y1] format\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1803\u001b[39m boxes = \u001b[43mcenter_to_corners_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_bbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[38;5;66;03m# Convert from relative [0, 1] to absolute [0, height] coordinates\u001b[39;00m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\image_transforms.py:577\u001b[39m, in \u001b[36mcenter_to_corners_format\u001b[39m\u001b[34m(bboxes_center)\u001b[39m\n\u001b[32m    574\u001b[39m \u001b[38;5;66;03m# Function is used during model forward pass, so we use the input framework if possible, without\u001b[39;00m\n\u001b[32m    575\u001b[39m \u001b[38;5;66;03m# converting to numpy\u001b[39;00m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_tensor(bboxes_center):\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_center_to_corners_format_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbboxes_center\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bboxes_center, np.ndarray):\n\u001b[32m    579\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _center_to_corners_format_numpy(bboxes_center)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\image_transforms.py:535\u001b[39m, in \u001b[36m_center_to_corners_format_torch\u001b[39m\u001b[34m(bboxes_center)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_center_to_corners_format_torch\u001b[39m(bboxes_center: \u001b[33m\"\u001b[39m\u001b[33mtorch.Tensor\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mtorch.Tensor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     center_x, center_y, width, height = \u001b[43mbboxes_center\u001b[49m\u001b[43m.\u001b[49m\u001b[43munbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m     bbox_corners = torch.stack(\n\u001b[32m    537\u001b[39m         \u001b[38;5;66;03m# top left x, top left y, bottom right x, bottom right y\u001b[39;00m\n\u001b[32m    538\u001b[39m         [(center_x - \u001b[32m0.5\u001b[39m * width), (center_y - \u001b[32m0.5\u001b[39m * height), (center_x + \u001b[32m0.5\u001b[39m * width), (center_y + \u001b[32m0.5\u001b[39m * height)],\n\u001b[32m    539\u001b[39m         dim=-\u001b[32m1\u001b[39m,\n\u001b[32m    540\u001b[39m     )\n\u001b[32m    541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bbox_corners\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#test_dir = r\"D:\\images\\HockingHills\"\n",
    "test_dir = r\"D:\\images\\images\"\n",
    "output = r\"D:\\images\\output\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 1. Instantiate the Dataloader\n",
    "# Using a small batch size for the example\n",
    "dataloader = ImageDataloader(root_dir=test_dir, batch_size=32)\n",
    "\n",
    "classifier = ImageClassifier(dataloader=dataloader, output_dir=output)\n",
    "\n",
    "try:\n",
    "    classifier.classify_images()\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during classification: {e}\")\n",
    "    print(\"This can happen if you are offline or models are unavailable.\")\n",
    "\n",
    "# 5. Print a summary\n",
    "print(\"\\n--- Final Output Summary ---\")\n",
    "try:\n",
    "    for category in os.listdir(output):\n",
    "        category_path = os.path.join(output, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            files = os.listdir(category_path)\n",
    "            print(f\"Files in '{category}': {len(files)} {files}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Output directory 'classification_output' not found. Did the script run?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
