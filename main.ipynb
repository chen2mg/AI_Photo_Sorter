{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ba3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEIC/HEIF support enabled.\n",
      "FaceAnalysis support enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import shutil\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Generator, Any\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter  \n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# --- HEIC/HEIF Support ---\n",
    "# This is required to make PIL.Image.open() support HEIC/HEIF formats.\n",
    "# You must install this library: pip install pillow-heif\n",
    "try:\n",
    "    import pillow_heif\n",
    "    pillow_heif.register_heif_opener()\n",
    "    print(\"HEIC/HEIF support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: 'pillow-heif' not installed. HEIC/HEIF files will be skipped.\")\n",
    "    print(\"Install with: pip install pillow-heif\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "try:\n",
    "    from insightface.app import FaceAnalysis\n",
    "    print(\"FaceAnalysis support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: FaceAnalysis not installed.\")\n",
    "    print(\"pip install insightface\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "# --- Hugging Face transformers ---\n",
    "# You must install this library: pip install transformers torch\n",
    "try:\n",
    "    from transformers import pipeline, Pipeline\n",
    "    from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"CRITICAL: 'transformers' or 'torch' not found.\")\n",
    "    print(\"Please install them to run this script: pip install transformers torch\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "class ImageDataloader:\n",
    "    \"\"\"\n",
    "    Scans a directory for unique images and provides batches for processing.\n",
    "\n",
    "    This class is implemented as a Python generator. It does not\n",
    "    inherit from torch.utils.data.DataLoader, as our use case\n",
    "    requires a simple, stateful iterator.\n",
    "    \"\"\"\n",
    "    IMAGE_EXTENSIONS: tuple = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "\n",
    "    def __init__(self, root_dir: str, batch_size: int = 32):\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"Root directory not found: {root_dir}\")\n",
    "        if batch_size <= 0:\n",
    "            raise ValueError(\"Batch size must be greater than 0\")\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.labels will hold the \"working state\" of all images\n",
    "        # {image_path: \"unknown\"}\n",
    "        self.labels: Dict[str, str] = {}\n",
    "        self._scan_and_deduplicate()\n",
    "\n",
    "    def _calculate_hash(self, filepath: str, block_size: int = 65536) -> str:\n",
    "        \"\"\"\n",
    "        Calculates the SHA256 hash of a file's content.\n",
    "        \"\"\"\n",
    "        sha256 = hashlib.sha256()\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                while chunk := f.read(block_size):\n",
    "                    sha256.update(chunk)\n",
    "            return sha256.hexdigest()\n",
    "        except (IOError, OSError) as e:\n",
    "            print(f\"Warning: Could not read file for hashing: {filepath}. Skipping. Error: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _scan_and_deduplicate(self):\n",
    "        \"\"\"\n",
    "        Walks the root directory, finds all unique images, and\n",
    "        populates self.labels with the default 'unknown' label.\n",
    "        \"\"\"\n",
    "        print(f\"Scanning directory: {self.root_dir}...\")\n",
    "        image_hashes: set[str] = set()\n",
    "        total_files = 0\n",
    "        duplicates_skipped = 0\n",
    "\n",
    "        for root, _, files in os.walk(self.root_dir):\n",
    "            for file in files:\n",
    "                if not file.lower().endswith(self.IMAGE_EXTENSIONS):\n",
    "                    continue\n",
    "\n",
    "                total_files += 1\n",
    "                full_path = os.path.join(root, file)\n",
    "                file_hash = self._calculate_hash(full_path)\n",
    "\n",
    "                if not file_hash:\n",
    "                    continue\n",
    "\n",
    "                if file_hash not in image_hashes:\n",
    "                    image_hashes.add(file_hash)\n",
    "                    # All images start as 'unknown'\n",
    "                    self.labels[full_path] = \"unknown\"\n",
    "                else:\n",
    "                    duplicates_skipped += 1\n",
    "\n",
    "        print(\"--- Scan Complete ---\")\n",
    "        print(f\"Total image files found: {total_files}\")\n",
    "        print(f\"Duplicate images skipped: {duplicates_skipped}\")\n",
    "        print(f\"Total unique images to process: {len(self.labels)}\")\n",
    "        if not self.labels:\n",
    "            print(\"Warning: No valid, unique images were found.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of unique images to be processed.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __iter__(self) -> Generator[Dict[str, str], None, None]:\n",
    "        \"\"\"\n",
    "        Yields batches of images as dictionaries {image_path: label}.\n",
    "        \"\"\"\n",
    "        # Get a static list of paths to iterate over\n",
    "        all_paths = list(self.labels.keys())\n",
    "        \n",
    "        for i in range(0, len(all_paths), self.batch_size):\n",
    "            batch_paths = all_paths[i : i + self.batch_size]\n",
    "            \n",
    "            # Create the batch dict\n",
    "            batch_data = {path: self.labels[path] for path in batch_paths}\n",
    "            \n",
    "            if batch_data:\n",
    "                yield batch_data\n",
    "\n",
    "\n",
    "class ImageClassifier:\n",
    "    \"\"\"\n",
    "    Uses a \"waterfall\" method to classify images from a dataloader\n",
    "    using multiple, chained AI models.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader: ImageDataloader, output_dir: str = \"output\"):\n",
    "        self.dataloader = dataloader\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # this variable save final prediction\n",
    "        self.processed_images = {}\n",
    "\n",
    "        # 1. Determine the device\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.pipeline_device = 0 if self.device == torch.device('cuda') else -1\n",
    "        print(f\"Using device: {self.device} (Pipeline device: {self.pipeline_device})\")\n",
    "        \n",
    "        self.output_paths = {\n",
    "            \"people\": os.path.join(output_dir, \"people\"),\n",
    "            \"view\": os.path.join(output_dir, \"view\"),\n",
    "            \"unknown\": os.path.join(output_dir, \"unknown\")\n",
    "        }\n",
    "        self._create_output_dirs()\n",
    "        \n",
    "        # --- Load Models in __init__ ---\n",
    "        print(\"Loading models...\")\n",
    "        \n",
    "        # Stage 1: Face Detector \n",
    "        self.retinaface_model = self.load_retinaface_model()\n",
    "        self.detr_pipeline = self.load_detr_pipeline()\n",
    "\n",
    "        # Stage 2: View Detector \n",
    "        self.clip_pipeline = self.load_clip_pipeline()\n",
    "\n",
    "        print(\"Model loading complete.\")\n",
    "\n",
    "\n",
    "    def _create_output_dirs(self):\n",
    "        \"\"\"Creates the output directories if they don't exist.\"\"\"\n",
    "        print(f\"Ensuring output directories exist at: {self.output_dir}\")\n",
    "        for path in self.output_paths.values():\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "    def _move_file(self, batch_data: Dict[str, str], action='move'):\n",
    "        \"\"\"\n",
    "        batch_data: dict {image_path: label}\n",
    "\n",
    "        Moves a batch of image files to their classified directories.\n",
    "        \"\"\"\n",
    "        assert action in ['move', 'copy']\n",
    "        # Iterate over each image path and its assigned label in the dictionary\n",
    "        for image_path, new_label in batch_data.items():\n",
    "            try:\n",
    "                # 1. Get destination directory. Default to 'unknown' if label is invalid.\n",
    "                dest_dir = self.output_paths.get(new_label, self.output_paths[\"unknown\"])\n",
    "                \n",
    "                # 2. Get the base filename from the full path\n",
    "                filename = os.path.basename(image_path)\n",
    "                \n",
    "                # 3. Create the full destination path\n",
    "                dest_path = os.path.join(dest_dir, filename)\n",
    "                \n",
    "\n",
    "                # 5. Move the file\n",
    "                if action=='move':\n",
    "                    shutil.move(image_path, dest_path)\n",
    "                else:\n",
    "                    shutil.copy2(image_path, dest_path)\n",
    "\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found, cannot move: {image_path}\")\n",
    "            except PermissionError:\n",
    "                print(f\"Permission denied, cannot move: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to move {image_path}: {e}\")\n",
    "\n",
    "\n",
    "    def _display_batch(self, batch_data: Dict[str, str], show_image=False):\n",
    "        \"\"\"\n",
    "        Displays a summary of batch data (category counts) and optionally\n",
    "        renders each image with its category as the title.\n",
    "\n",
    "        Args:\n",
    "            batch_data (Dict[str, str]): Dictionary where keys are file paths \n",
    "                                        and values are the categories/labels.\n",
    "            show_image (bool): A flag to control whether to display images.\n",
    "        \"\"\"\n",
    "        # --- Batch Summary Section ---\n",
    "        \n",
    "        # Use collections.Counter to efficiently count the occurrences of each \n",
    "        # unique value (category) in the batch_data dictionary.\n",
    "        value_counts = Counter(batch_data.values())\n",
    "        \n",
    "        print(\"Counts for each unique value in this batch:\")\n",
    "        \n",
    "        # Loop through the resulting Counter object (value_counts.items())\n",
    "        for value, count in value_counts.items():\n",
    "            # Prints each unique value and its total count\n",
    "            print(f\"  Image category '{value}': {count} time(s)\")\n",
    "            \n",
    "        print(\"-----------------------------------------\")\n",
    "        \n",
    "        # --- Image Display Section ---\n",
    "        \n",
    "        # This entire block is conditional. It only runs if show_image=True\n",
    "        if show_image:\n",
    "            for key in batch_data:\n",
    "                # Print the file path being processed\n",
    "                print(key)\n",
    "                plt.title(batch_data[key])\n",
    "                plt.imshow(Image.open(key).convert('RGB'))\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "    def classify_images(self):\n",
    "        \"\"\"\n",
    "        The main classification loop (orchestrator).\n",
    "        Iterates through all batches and applies the waterfall logic.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Starting Image Classification Waterfall ---\")\n",
    "        total_batches = (len(self.dataloader) + self.dataloader.batch_size - 1) // self.dataloader.batch_size\n",
    "        \n",
    "        for i, initial_batch in enumerate(self.dataloader):\n",
    "            print(f\"\\nProcessing Batch {i+1} / {total_batches} (Size: {len(initial_batch)})...\")\n",
    "            \n",
    "            remaining_batch = initial_batch.copy()\n",
    "\n",
    "            # --- STAGE 1: Detect faces ---\n",
    "            if self.retinaface_model:\n",
    "                remaining_batch = self.detect_human_detr_pipeline(remaining_batch, self.detr_pipeline)\n",
    "            \n",
    "            # --- STAGE 1: Detect people ---\n",
    "            if self.retinaface_model:\n",
    "                remaining_batch = self.detect_with_RetinaFace(remaining_batch, self.retinaface_model)\n",
    "\n",
    "            # --- STAGE 2: View Models ---\n",
    "            if self.clip_pipeline:\n",
    "                remaining_batch = self.detect_view_clip_pipeline(\n",
    "                    remaining_batch, self.clip_pipeline,\n",
    "                    target_label=\"view\",\n",
    "                    prompts=[\"a photo of a landscape\", \"a beautiful view\", \"a flower\", \"a photo of food\", \"a city skyline\", \"a beach\", \"mountains\", \"a forest\"]\n",
    "                )\n",
    "\n",
    "\n",
    "            self._move_file(remaining_batch, 'copy')\n",
    "            self.processed_images |=remaining_batch\n",
    "            print(f\"Batch {i+1} complete.\")\n",
    "        \n",
    "        self._display_batch(self.processed_images)\n",
    "\n",
    "        print(\"\\n--- Image Classification Finished ---\")\n",
    "\n",
    "    # --- Specific Model Classification Methods ---\n",
    "    # --- Specific retinaface Model ---\n",
    "    def load_retinaface_model(self):\n",
    "        # try:\n",
    "        #     app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "        #     app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "        #     print(\"Loaded: retinaface\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"CRITICAL: Failed to load retinaface. {e}\")\n",
    "        #     app = None\n",
    "\n",
    "        app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "        app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "        return app\n",
    "    \n",
    "\n",
    "    def detect_with_RetinaFace(self, batch_data, model, target_label='people'):\n",
    "        \"\"\"\n",
    "        batch_data: dict {image_path: label}\n",
    "        model: RetinaFace model (insightface FaceAnalysis)\n",
    "\n",
    "        Processes only images labeled 'unknown'.\n",
    "        Returns updated batch_data with detections.\n",
    "        \"\"\"\n",
    "        updated_data = batch_data.copy()\n",
    "\n",
    "        # 1️⃣ Filter for unknown images\n",
    "        unknown_items = [(path, label) for path, label in batch_data.items() if label == \"unknown\"]\n",
    "        if not unknown_items:\n",
    "            return updated_data\n",
    "        \n",
    "        print(f\"\\nProcessing {len(unknown_items)} 'unknown' images using the RetinaFace model...\")\n",
    "\n",
    "        image_paths = [p for p, _ in unknown_items]\n",
    "\n",
    "        # 2️⃣ Load all images once\n",
    "        loaded_images = {}\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_bgr = np.array(img)[:, :, ::-1]  # RGB → BGR\n",
    "                loaded_images[img_path] = img_bgr\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error reading {img_path}: {e}\")\n",
    "                updated_data[img_path] = \"invalid\"\n",
    "\n",
    "        update_count=0\n",
    "        # 3️⃣ Run inference per image (insightface doesn't support batch)\n",
    "        for img_path, img_bgr in loaded_images.items():\n",
    "            faces = model.get(img_bgr)  # must be called one by one\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                updated_data[img_path] = target_label\n",
    "                update_count+=1\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(unknown_items)} images using detr. Updated {update_count} labels to '{target_label}'.\")\n",
    "        return updated_data\n",
    "\n",
    "    # --- Specific detr Model ---\n",
    "    def load_detr_pipeline(self):\n",
    "        try:\n",
    "            model = \"facebook/detr-resnet-50\"\n",
    "            detr_pipeline = pipeline(\"object-detection\", model=model, device=self.pipeline_device)\n",
    "            print(\"Loaded: facebook/detr-resnet-50\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load DETR. {e}\")\n",
    "            detr_pipeline = None\n",
    "        return detr_pipeline\n",
    "\n",
    "    def detect_human_detr_pipeline(self, batch_data: Dict[str, str], detr_pipeline: Any, target_label='people') -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Detects humans ('person' label) in ALL images labeled 'unknown' using the \n",
    "        Hugging Face pipeline in a single batch operation and updates the labels.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            detr_pipeline (transformers.Pipeline): The loaded DETR object detection pipeline.\n",
    "            confidence_threshold (float): Minimum confidence for a detection to be considered.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        # DETR is trained on COCO, where the label for a human is 'person'\n",
    "        PERSON_LABEL = 'person' \n",
    "        confidence_threshold = 0.9\n",
    "\n",
    "        if detr_pipeline is None:\n",
    "            print(\"ERROR: Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        print(f\"\\nProcessing all {len(unknown_paths)} 'unknown' images using the detr pipeline...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # The pipeline handles moving data to the device defined during load.\n",
    "        # We pass the list of PIL images directly.\n",
    "        try:\n",
    "            # The result is a list of lists: [[det1, det2, ...], [det1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = detr_pipeline(batch_images)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        update_count = 0\n",
    "        # 3. Post-process the results\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            is_human_detected = False\n",
    "            \n",
    "            # image_results is a list of dictionaries (one for each detection)\n",
    "            for detection in image_results:\n",
    "                # The pipeline provides the score and the label (e.g., 'person')\n",
    "                if detection['score'] >= confidence_threshold and detection['label'] == PERSON_LABEL:\n",
    "                    is_human_detected = True\n",
    "                    # print(f\"✅ Detected {PERSON_LABEL} in: {image_path} with score {detection['score']:.2f}\")\n",
    "                    break # Found a person, no need to check other detections for this image\n",
    "\n",
    "            if is_human_detected:\n",
    "                batch_data[image_path] = target_label\n",
    "                update_count+=1\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using detr. Updated {update_count} labels to '{target_label}'.\")\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "    # --- Specific clip Model ---\n",
    "    def load_clip_pipeline(self):\n",
    "        \"\"\"\n",
    "        Loads the CLIP zero-shot classification pipeline.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            clip_pipeline = pipeline(\n",
    "                \"zero-shot-image-classification\",\n",
    "                model=\"openai/clip-vit-large-patch14\",\n",
    "                device=self.pipeline_device  \n",
    "            )\n",
    "            print(\"Loaded: clip-vit-large-patch14\")\n",
    "            return clip_pipeline  # <-- FIX: You must return the loaded pipeline\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load CLIP. {e}\")\n",
    "            return None # Return None on failure\n",
    "\n",
    "    def detect_view_clip_pipeline(self, batch_data: Dict[str, str], clip_pipeline: Any, target_label: str, prompts: List[str], confidence_threshold: float = 0.80) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classifies images labeled 'unknown' using the CLIP pipeline and a list of prompts.\n",
    "        \n",
    "        If the top-scoring prompt meets the confidence threshold, the image label\n",
    "        is updated to the single `target_label`.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            clip_pipeline (transformers.Pipeline): The loaded CLIP pipeline.\n",
    "            target_label (str): The new label to assign if a match is found (e.g., 'view').\n",
    "            prompts (list): A list of candidate labels to check against (e.g., \"a flower\").\n",
    "            confidence_threshold (float): Minimum confidence for a classification.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        if clip_pipeline is None:\n",
    "            print(\"ERROR: CLIP Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found for CLIP processing. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        print(f\"\\nProcessing {len(unknown_paths)} 'unknown' images using CLIP with {len(prompts)} prompts...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded for CLIP. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # We pass the list of PIL images and the candidate labels\n",
    "        try:\n",
    "            # The result is a list of lists: [[class1, class2, ...], [class1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = clip_pipeline(\n",
    "                batch_images, \n",
    "                candidate_labels=prompts\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during CLIP pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 3. Post-process the results\n",
    "        update_count = 0\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            \n",
    "            # The pipeline returns all prompts, sorted by score.\n",
    "            # We only care about the top-scoring one.\n",
    "            top_detection = image_results[0]\n",
    "            \n",
    "            # Check if the top score meets our threshold.\n",
    "            # Since the pipeline only returns labels from our `prompts` list,\n",
    "            # we know the label is one we are looking for.\n",
    "            if top_detection['score'] >= confidence_threshold:\n",
    "                # print(f\"✅ Classified {image_path} as '{top_detection['label']}' (score: {top_detection['score']:.2f}). Setting label to '{target_label}'.\")\n",
    "                \n",
    "                # Update the label to the generic target_label\n",
    "                batch_data[image_path] = target_label\n",
    "                update_count += 1\n",
    "            else:\n",
    "                # The top score was too low, so we \"leave it\" (it remains 'unknown')\n",
    "                pass\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using CLIP. Updated {update_count} labels to '{target_label}'.\")\n",
    "        return batch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d7361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: D:\\images\\images...\n",
      "--- Scan Complete ---\n",
      "Total image files found: 8619\n",
      "Duplicate images skipped: 0\n",
      "Total unique images to process: 8619\n",
      "Using device: cuda (Pipeline device: 0)\n",
      "Ensuring output directories exist at: D:\\images\\output\n",
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\xiaom/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer1.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer2.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer3.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2397: UserWarning: for layer4.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: facebook/detr-resnet-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: clip-vit-large-patch14\n",
      "Model loading complete.\n",
      "\n",
      "--- Starting Image Classification Waterfall ---\n",
      "\n",
      "Processing Batch 1 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 1 complete.\n",
      "\n",
      "Processing Batch 2 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 2 complete.\n",
      "\n",
      "Processing Batch 3 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 3 complete.\n",
      "\n",
      "Processing Batch 4 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 4 complete.\n",
      "\n",
      "Processing Batch 5 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 5 complete.\n",
      "\n",
      "Processing Batch 6 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 6 complete.\n",
      "\n",
      "Processing Batch 7 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 7 complete.\n",
      "\n",
      "Processing Batch 8 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 8 complete.\n",
      "\n",
      "Processing Batch 9 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 29 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 3 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 3 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 9 complete.\n",
      "\n",
      "Processing Batch 10 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 10 complete.\n",
      "\n",
      "Processing Batch 11 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 11 complete.\n",
      "\n",
      "Processing Batch 12 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 12 complete.\n",
      "\n",
      "Processing Batch 13 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 13 complete.\n",
      "\n",
      "Processing Batch 14 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 14 complete.\n",
      "\n",
      "Processing Batch 15 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 15 complete.\n",
      "\n",
      "Processing Batch 16 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 16 complete.\n",
      "\n",
      "Processing Batch 17 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 17 complete.\n",
      "\n",
      "Processing Batch 18 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 18 complete.\n",
      "\n",
      "Processing Batch 19 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 29 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 3 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 19 complete.\n",
      "\n",
      "Processing Batch 20 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 20 complete.\n",
      "\n",
      "Processing Batch 21 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 29 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 3 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 21 complete.\n",
      "\n",
      "Processing Batch 22 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 22 complete.\n",
      "\n",
      "Processing Batch 23 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 28 labels to 'people'.\n",
      "\n",
      "Processing 4 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 4 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 3 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 3 images using CLIP. Updated 1 labels to 'view'.\n",
      "Batch 23 complete.\n",
      "\n",
      "Processing Batch 24 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 24 complete.\n",
      "\n",
      "Processing Batch 25 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 25 complete.\n",
      "\n",
      "Processing Batch 26 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 1 labels to 'view'.\n",
      "Batch 26 complete.\n",
      "\n",
      "Processing Batch 27 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 27 complete.\n",
      "\n",
      "Processing Batch 28 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 28 complete.\n",
      "\n",
      "Processing Batch 29 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 29 complete.\n",
      "\n",
      "Processing Batch 30 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 30 complete.\n",
      "\n",
      "Processing Batch 31 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 31 complete.\n",
      "\n",
      "Processing Batch 32 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 32 complete.\n",
      "\n",
      "Processing Batch 33 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 33 complete.\n",
      "\n",
      "Processing Batch 34 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 34 complete.\n",
      "\n",
      "Processing Batch 35 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 35 complete.\n",
      "\n",
      "Processing Batch 36 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 36 complete.\n",
      "\n",
      "Processing Batch 37 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 1 labels to 'view'.\n",
      "Batch 37 complete.\n",
      "\n",
      "Processing Batch 38 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 38 complete.\n",
      "\n",
      "Processing Batch 39 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 39 complete.\n",
      "\n",
      "Processing Batch 40 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 40 complete.\n",
      "\n",
      "Processing Batch 41 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 41 complete.\n",
      "\n",
      "Processing Batch 42 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 42 complete.\n",
      "\n",
      "Processing Batch 43 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 2 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 43 complete.\n",
      "\n",
      "Processing Batch 44 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 44 complete.\n",
      "\n",
      "Processing Batch 45 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 45 complete.\n",
      "\n",
      "Processing Batch 46 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 46 complete.\n",
      "\n",
      "Processing Batch 47 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 47 complete.\n",
      "\n",
      "Processing Batch 48 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 48 complete.\n",
      "\n",
      "Processing Batch 49 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 1 labels to 'view'.\n",
      "Batch 49 complete.\n",
      "\n",
      "Processing Batch 50 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 50 complete.\n",
      "\n",
      "Processing Batch 51 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 51 complete.\n",
      "\n",
      "Processing Batch 52 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 52 complete.\n",
      "\n",
      "Processing Batch 53 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 53 complete.\n",
      "\n",
      "Processing Batch 54 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 2 labels to 'view'.\n",
      "Batch 54 complete.\n",
      "\n",
      "Processing Batch 55 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 55 complete.\n",
      "\n",
      "Processing Batch 56 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 56 complete.\n",
      "\n",
      "Processing Batch 57 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 57 complete.\n",
      "\n",
      "Processing Batch 58 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 58 complete.\n",
      "\n",
      "Processing Batch 59 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 27 labels to 'people'.\n",
      "\n",
      "Processing 5 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 5 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 5 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 5 images using CLIP. Updated 2 labels to 'view'.\n",
      "Batch 59 complete.\n",
      "\n",
      "Processing Batch 60 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 60 complete.\n",
      "\n",
      "Processing Batch 61 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 61 complete.\n",
      "\n",
      "Processing Batch 62 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 1 labels to 'view'.\n",
      "Batch 62 complete.\n",
      "\n",
      "Processing Batch 63 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 63 complete.\n",
      "\n",
      "Processing Batch 64 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 64 complete.\n",
      "\n",
      "Processing Batch 65 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 65 complete.\n",
      "\n",
      "Processing Batch 66 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 1 labels to 'view'.\n",
      "Batch 66 complete.\n",
      "\n",
      "Processing Batch 67 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 31 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 1 images using detr. Updated 1 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 67 complete.\n",
      "\n",
      "Processing Batch 68 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 68 complete.\n",
      "\n",
      "Processing Batch 69 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 1 labels to 'people'.\n",
      "\n",
      "Processing 1 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 1 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 69 complete.\n",
      "\n",
      "Processing Batch 70 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 70 complete.\n",
      "\n",
      "Processing Batch 71 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 71 complete.\n",
      "\n",
      "Processing Batch 72 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 72 complete.\n",
      "\n",
      "Processing Batch 73 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 73 complete.\n",
      "\n",
      "Processing Batch 74 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 74 complete.\n",
      "\n",
      "Processing Batch 75 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 2 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 75 complete.\n",
      "\n",
      "Processing Batch 76 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 32 labels to 'people'.\n",
      "No images labeled 'unknown' found for CLIP processing. Returning original data.\n",
      "Batch 76 complete.\n",
      "\n",
      "Processing Batch 77 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n",
      "\n",
      "Successfully processed 32 images using detr. Updated 30 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using the RetinaFace model...\n",
      "\n",
      "Successfully processed 2 images using detr. Updated 0 labels to 'people'.\n",
      "\n",
      "Processing 2 'unknown' images using CLIP with 8 prompts...\n",
      "\n",
      "Successfully processed 2 images using CLIP. Updated 0 labels to 'view'.\n",
      "Batch 77 complete.\n",
      "\n",
      "Processing Batch 78 / 270 (Size: 32)...\n",
      "\n",
      "Processing all 32 'unknown' images using the detr pipeline...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test_dir = r\"D:\\images\\HockingHills\"\n",
    "test_dir = r\"D:\\images\\images\"\n",
    "output = r\"D:\\images\\output\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 1. Instantiate the Dataloader\n",
    "# Using a small batch size for the example\n",
    "dataloader = ImageDataloader(root_dir=test_dir, batch_size=32)\n",
    "\n",
    "classifier = ImageClassifier(dataloader=dataloader, output_dir=output)\n",
    "\n",
    "try:\n",
    "    classifier.classify_images()\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during classification: {e}\")\n",
    "    print(\"This can happen if you are offline or models are unavailable.\")\n",
    "\n",
    "# 5. Print a summary\n",
    "print(\"\\n--- Final Output Summary ---\")\n",
    "try:\n",
    "    for category in os.listdir(output):\n",
    "        category_path = os.path.join(output, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            files = os.listdir(category_path)\n",
    "            print(f\"Files in '{category}': {len(files)} {files}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Output directory 'classification_output' not found. Did the script run?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
