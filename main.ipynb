{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9cd70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "AI Photo Sorter (v6 - Hybrid Detection/Classification)\n",
    "Sorts a directory of images using a multi-stage \"waterfall\" classification\n",
    "process that combines specialized object detectors with powerful CLIP models\n",
    "for high-accuracy sorting.\n",
    "\n",
    "This version implements a new 5-pass logic:\n",
    "1. Pass 1: Face Detector (MobileFaceDet)\n",
    "2. Pass 2: Person Detector (DETR)\n",
    "3. Pass 3: Human Classifier (CLIP-L-14)\n",
    "4. Pass 4: View Classifier (CLIP-L-14)\n",
    "5. Pass 5: View Classifier (CLIP-L-14-336)\n",
    "6. Remaining images are classified as 'junk'.\n",
    "\n",
    "REQUIREMENTS:\n",
    "pip install torch transformers Pillow pillow-heif\n",
    "\n",
    "--- USAGE IN JUPYTER NOTEBOOK ---\n",
    "(Usage is identical to v5)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import hashlib\n",
    "import traceback\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Dependency Imports (grouped for checking) ---\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    Image = None\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except ImportError:\n",
    "    torch = None\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "except ImportError:\n",
    "    pipeline = None\n",
    "\n",
    "try:\n",
    "    import pillow_heif\n",
    "except ImportError:\n",
    "    pillow_heif = None\n",
    "\n",
    "\n",
    "class AIPhotoSorter:\n",
    "    \"\"\"\n",
    "    Encapsulates all logic for scanning, classifying, and sorting images\n",
    "    using a multi-stage hybrid waterfall classification system.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Constants as Class Attributes ---\n",
    "    BATCH_SIZE_DEFAULT = 32\n",
    "    IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "    HASH_CHUNK_SIZE = 8192  # Read files in 8KB chunks for hashing\n",
    "\n",
    "    # --- NEW: Labels and Thresholds for Hybrid Waterfall Logic ---\n",
    "    \n",
    "    # Stage 1: Face Detector\n",
    "    FACE_DETECTOR_THRESHOLD = 0.9  # High confidence for 'face'\n",
    "\n",
    "    # Stage 2: Person Detector\n",
    "    PERSON_DETECTOR_LABEL = 'person'\n",
    "    PERSON_DETECTOR_THRESHOLD = 0.9 # High confidence for 'person'\n",
    "\n",
    "    # Stage 3: Human Classifier (CLIP)\n",
    "    HUMAN_LABELS = [\n",
    "        \"a photo of a person\", \"a photo of a face\", \"a portrait\", \"a selfie\",\n",
    "        \"a photo of a baby\", \"a photo of a child\", \"a photo of a family\",\n",
    "        \"a photo of a group of people\"\n",
    "    ]\n",
    "    HUMAN_CLIP_THRESHOLD = 0.7  # For openai/clip-vit-large-patch14\n",
    "\n",
    "    # Stage 4 & 5: View Classifiers (CLIP)\n",
    "    VIEW_LABELS = [\n",
    "        \"a scenic landscape\", \"a photo of a mountain\", \"a photo of a beach\",\n",
    "        \"a photo of a flower\", \"a photo of a forest\", \"a photo of a sunset\",\n",
    "        \"a photo of a building\", \"architecture\", \"a photo of a city\",\n",
    "        \"a photo of delicious food\", \"a photo of a meal\"\n",
    "    ]\n",
    "    VIEW_CLIP_L14_THRESHOLD = 0.75 # For openai/clip-vit-large-patch14\n",
    "    VIEW_CLIP_L14_336_THRESHOLD = 0.75 # For openai/clip-vit-large-patch14-336\n",
    "\n",
    "\n",
    "    def __init__(self, root_path, output_path, batch_size=BATCH_SIZE_DEFAULT):\n",
    "        self.root_path = root_path\n",
    "        self.output_path = output_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Output directories\n",
    "        self.output_dirs = {\n",
    "            \"family_photos\": os.path.join(self.output_path, \"family_photos\"),\n",
    "            \"views\": os.path.join(self.output_path, \"views\"),\n",
    "            \"junk\": os.path.join(self.output_path, \"junk\")\n",
    "        }\n",
    "\n",
    "        # --- NEW: AI Models for Hybrid Waterfall ---\n",
    "        self.face_detector_pipeline = None  # d-li/mobilefacedet\n",
    "        self.person_detector_pipeline = None # facebook/detr-resnet-50\n",
    "        self.clip_l14_pipeline = None      # openai/clip-vit-large-patch14\n",
    "        self.clip_l14_336_pipeline = None  # openai/clip-vit-large-patch14-336\n",
    "        \n",
    "        # State\n",
    "        self.seen_hashes = {}\n",
    "        self.unique_image_paths = []\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = defaultdict(int)\n",
    "\n",
    "    @staticmethod\n",
    "    def check_dependencies():\n",
    "        \"\"\"\n",
    "        Checks if all required libraries are installed.\n",
    "        Raises ImportError if a critical one is missing.\n",
    "        \"\"\"\n",
    "        print(\"Checking dependencies...\")\n",
    "        if Image is None:\n",
    "            raise ImportError(\"Error: 'Pillow' library not found. Please install with: pip install Pillow\")\n",
    "        if torch is None:\n",
    "            raise ImportError(\"Error: 'torch' library not found. Please install with: pip install torch\")\n",
    "        if pipeline is None:\n",
    "            raise ImportError(\"Error: 'transformers' library not found. Please install with: pip install transformers\")\n",
    "        \n",
    "        if pillow_heif is None:\n",
    "            print(\"Warning: 'pillow-heif' library not found. HEIC/HEIF files will not be processed.\", file=sys.stderr)\n",
    "            print(\"Install with: pip install pillow-heif\", file=sys.stderr)\n",
    "        else:\n",
    "            pillow_heif.register_heif_opener()\n",
    "            print(\"HEIF/HEIC support enabled.\")\n",
    "        print(\"All critical dependencies are present.\")\n",
    "\n",
    "    # --- Public Entry Point ---\n",
    "\n",
    "    def run_sort(self):\n",
    "        \"\"\"\n",
    "        Executes the entire sorting process from start to finish.\n",
    "        This is the main public method to call.\n",
    "        \"\"\"\n",
    "        print(\"--- AI Photo Sorter (v6) ---\")\n",
    "        print(f\"Source: {self.root_path}\")\n",
    "        print(f\"Destination: {self.output_path}\")\n",
    "        print(f\"Batch Size: {self.batch_size}\")\n",
    "        print(\"-\" * 25)\n",
    "\n",
    "        try:\n",
    "            self._setup_output_dirs()\n",
    "            self._load_models()\n",
    "            self._run_pass_1_scan_files()\n",
    "            self._run_pass_2_process_batches()\n",
    "            self._print_final_report()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n--- [FATAL ERROR] ---\", file=sys.stderr)\n",
    "            print(f\"An unexpected error occurred: {e}\", file=sys.stderr)\n",
    "            traceback.print_exc(file=sys.stderr)\n",
    "\n",
    "    # --- Private Methods: Setup ---\n",
    "\n",
    "    def _setup_output_dirs(self):\n",
    "        \"\"\"Creates all necessary output directories.\"\"\"\n",
    "        print(\"Setting up output directories...\")\n",
    "        for dir_path in self.output_dirs.values():\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "        print(\"Output directories ready.\")\n",
    "\n",
    "    def _load_models(self):\n",
    "        \"\"\"Loads and initializes the four AI models (pipelines).\"\"\"\n",
    "        print(\"Loading AI models... (This may take a few minutes and download files on first run)\")\n",
    "        try:\n",
    "            device = 0 if torch.cuda.is_available() else -1\n",
    "            \n",
    "            print(\"Loading Model 1: d-li/mobilefacedet (Face Detector)...\")\n",
    "            self.face_detector_pipeline = pipeline(\n",
    "                \"object-detection\",\n",
    "                model=\"d-li/mobilefacedet\",\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            print(\"Loading Model 2: facebook/detr-resnet-50 (Person Detector)...\")\n",
    "            self.person_detector_pipeline = pipeline(\n",
    "                \"object-detection\",\n",
    "                model=\"facebook/detr-resnet-50\",\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            print(\"Loading Model 3: openai/clip-vit-large-patch14 (Classifier)...\")\n",
    "            self.clip_l14_pipeline = pipeline(\n",
    "                \"zero-shot-image-classification\",\n",
    "                model=\"openai/clip-vit-large-patch14\",\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            print(\"Loading Model 4: openai/clip-vit-large-patch14-336 (Classifier)...\")\n",
    "            self.clip_l14_336_pipeline = pipeline(\n",
    "                \"zero-shot-image-classification\",\n",
    "                model=\"openai/clip-vit-large-patch14-336\",\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            print(\"Models loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading models: {e}\", file=sys.stderr)\n",
    "            print(\"Please ensure you have an internet connection.\", file=sys.stderr)\n",
    "            raise # Re-raise to stop the process\n",
    "\n",
    "    # --- Private Methods: Pass 1 (Scanning) ---\n",
    "\n",
    "    def _run_pass_1_scan_files(self):\n",
    "        \"\"\"\n",
    "        Recursively scans the root_path, finds all images, calculates hashes,\n",
    "        and builds a de-duplicated list of unique images to process.\n",
    "        \"\"\"\n",
    "        # (This method is identical to v5)\n",
    "        print(\"\\n--- Pass 1: Scanning for duplicates and building file list ---\")\n",
    "        \n",
    "        for dirpath, _, filenames in os.walk(self.root_path):\n",
    "            print(f\"Scanning: {dirpath}\")\n",
    "            for filename in filenames:\n",
    "                if not filename.lower().endswith(self.IMAGE_EXTENSIONS):\n",
    "                    continue\n",
    "                \n",
    "                self.stats['total_files_scanned'] += 1\n",
    "                full_path = os.path.join(dirpath, filename)\n",
    "\n",
    "                file_hash = self._calculate_hash(full_path)\n",
    "                if not file_hash:\n",
    "                    self.stats['total_errors_pass1'] += 1\n",
    "                    continue\n",
    "\n",
    "                if file_hash in self.seen_hashes:\n",
    "                    print(f\"   -> Duplicate of: {self.seen_hashes[file_hash]} (Skipping)\")\n",
    "                    self.stats['skipped_duplicates'] += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    self.seen_hashes[file_hash] = full_path\n",
    "                    self.unique_image_paths.append(full_path)\n",
    "\n",
    "        print(f\"\\n--- Pass 1 Complete ---\")\n",
    "        print(f\"Total files scanned: {self.stats['total_files_scanned']}\")\n",
    "        print(f\"Duplicate files found: {self.stats['skipped_duplicates']}\")\n",
    "        print(f\"Unique images to process: {len(self.unique_image_paths)}\")\n",
    "        print(f\"Hashing/Read errors: {self.stats['total_errors_pass1']}\")\n",
    "\n",
    "    # --- Private Methods: Pass 2 (Processing) ---\n",
    "\n",
    "    def _run_pass_2_process_batches(self):\n",
    "        \"\"\"\n",
    "        Iterates over the list of unique image paths in fixed-size batches\n",
    "        and calls _process_one_batch for each.\n",
    "        \"\"\"\n",
    "        # (This method is identical to v5)\n",
    "        print(\"\\n--- Pass 2: Processing unique images in batches ---\")\n",
    "        \n",
    "        num_batches = (len(self.unique_image_paths) + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        for i in range(0, len(self.unique_image_paths), self.batch_size):\n",
    "            batch_paths = self.unique_image_paths[i : i + self.batch_size]\n",
    "            current_batch_num = (i // self.batch_size) + 1\n",
    "            \n",
    "            print(f\"\\nProcessing Batch {current_batch_num} / {num_batches} (Size: {len(batch_paths)})...\")\n",
    "            \n",
    "            try:\n",
    "                self._process_one_batch(batch_paths)\n",
    "            except Exception as e:\n",
    "                print(f\"   [CRITICAL BATCH ERROR] Failed to process batch: {e}\", file=sys.stderr)\n",
    "                print(\"     -> Skipping this entire batch. These files will not be moved.\", file=sys.stderr)\n",
    "                traceback.print_exc(file=sys.stderr)\n",
    "                self.stats['total_errors_pass2'] += len(batch_paths)\n",
    "\n",
    "    def _process_one_batch(self, batch_paths):\n",
    "        \"\"\"\n",
    "        Processes a single batch of images through the 5-stage hybrid waterfall.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Load image objects for this batch\n",
    "        valid_paths_in_batch, batch_image_objects = self._load_batch_images(batch_paths)\n",
    "        \n",
    "        if not batch_image_objects:\n",
    "            print(\"   -> All images in batch failed to load. Skipping.\")\n",
    "            return\n",
    "\n",
    "        # This tracks which *original index* in the batch still needs processing\n",
    "        remaining_indices = list(range(len(batch_image_objects)))\n",
    "        # This stores the final decision for each *original index*\n",
    "        final_decisions = {} # { 0: (\"family_photos\", \"face\"), 1: (\"junk\", \"other\"), ... }\n",
    "\n",
    "        # --- Helper for Object Detection Pass ---\n",
    "        def _run_object_detection_pass(model, images, indices, target_labels, threshold, category_name):\n",
    "            if not images:\n",
    "                return\n",
    "            \n",
    "            print(f\"   Running Pass ({category_name} Detector) on {len(images)} images...\")\n",
    "            all_results = self._run_object_detection_batch(model, images)\n",
    "            \n",
    "            # Iterate backwards so we can safely remove indices\n",
    "            for i in range(len(indices) - 1, -1, -1):\n",
    "                original_index = indices[i]\n",
    "                detections = all_results[i] # This is a list of dicts\n",
    "                \n",
    "                found_match = False\n",
    "                for obj in detections:\n",
    "                    if obj['label'] in target_labels and obj['score'] > threshold:\n",
    "                        final_decisions[original_index] = (category_name, obj['label'])\n",
    "                        indices.pop(i) # Remove index from remaining list\n",
    "                        found_match = True\n",
    "                        break # Move to the next image\n",
    "        \n",
    "        # --- Helper for Classification Pass ---\n",
    "        def _run_classification_pass(model, images, indices, labels, threshold, category_name):\n",
    "            if not images:\n",
    "                return\n",
    "            \n",
    "            print(f\"   Running Pass ({category_name} Classifier) on {len(images)} images...\")\n",
    "            results = self._run_zero_shot_batch(model, images, labels)\n",
    "            \n",
    "            for i in range(len(indices) - 1, -1, -1):\n",
    "                original_index = indices[i]\n",
    "                result = results[i][0] # Get top result\n",
    "                \n",
    "                if result['label'] in labels and result['score'] > threshold:\n",
    "                    final_decisions[original_index] = (category_name, result['label'])\n",
    "                    indices.pop(i)\n",
    "        \n",
    "        # --- Stage 1: Face Detector Pass ---\n",
    "        images_to_check = [batch_image_objects[i] for i in remaining_indices]\n",
    "        _run_object_detection_pass(self.face_detector_pipeline, images_to_check, remaining_indices, \n",
    "                                   {'face'}, self.FACE_DETECTOR_THRESHOLD, \"family_photos\")\n",
    "\n",
    "        # --- Stage 2: Person Detector Pass ---\n",
    "        images_to_check = [batch_image_objects[i] for i in remaining_indices]\n",
    "        _run_object_detection_pass(self.person_detector_pipeline, images_to_check, remaining_indices, \n",
    "                                   {self.PERSON_DETECTOR_LABEL}, self.PERSON_DETECTOR_THRESHOLD, \"family_photos\")\n",
    "\n",
    "        # --- Stage 3: Human Classifier (CLIP L-14) ---\n",
    "        images_to_check = [batch_image_objects[i] for i in remaining_indices]\n",
    "        _run_classification_pass(self.clip_l14_pipeline, images_to_check, remaining_indices, \n",
    "                                 self.HUMAN_LABELS, self.HUMAN_CLIP_THRESHOLD, \"family_photos\")\n",
    "\n",
    "        # --- Stage 4: View Classifier (CLIP L-14) ---\n",
    "        images_to_check = [batch_image_objects[i] for i in remaining_indices]\n",
    "        _run_classification_pass(self.clip_l14_pipeline, images_to_check, remaining_indices, \n",
    "                                 self.VIEW_LABELS, self.VIEW_CLIP_L14_THRESHOLD, \"views\")\n",
    "\n",
    "        # --- Stage 5: View Classifier (CLIP L-14-336) ---\n",
    "        images_to_check = [batch_image_objects[i] for i in remaining_indices]\n",
    "        _run_classification_pass(self.clip_l14_336_pipeline, images_to_check, remaining_indices, \n",
    "                                 self.VIEW_LABELS, self.VIEW_CLIP_L14_336_THRESHOLD, \"views\")\n",
    "\n",
    "        # --- Stage 6: Junk Pass ---\n",
    "        print(f\"   ... {len(remaining_indices)} images remaining, classifying as 'junk'.\")\n",
    "        for index in remaining_indices:\n",
    "            final_decisions[index] = (\"junk\", \"other\")\n",
    "            \n",
    "        # --- Final Step: Move Files ---\n",
    "        print(\"   Moving files to destinations...\")\n",
    "        for i in range(len(valid_paths_in_batch)):\n",
    "            full_path = valid_paths_in_batch[i]\n",
    "            original_filename = os.path.basename(full_path)\n",
    "            \n",
    "            dest_folder_name, label = final_decisions[i]\n",
    "            \n",
    "            dest_dir = self.output_dirs[dest_folder_name]\n",
    "            dest_path = self._get_unique_dest_path(dest_dir, original_filename)\n",
    "            \n",
    "            try:\n",
    "                shutil.move(full_path, dest_path)\n",
    "                print(f\"     -> Moved {original_filename} to {dest_folder_name} (as: {label})\")\n",
    "                self.stats['processed_files_moved'] += 1\n",
    "            except Exception as e:\n",
    "                print(f\"   [Error] Failed to move {original_filename}: {e}\", file=sys.stderr)\n",
    "                self.stats['total_errors_pass2'] += 1\n",
    "\n",
    "\n",
    "    def _load_batch_images(self, batch_paths):\n",
    "        \"\"\"Helper to load all images for a batch, skipping failures.\"\"\"\n",
    "        # (This method is identical to v5)\n",
    "        batch_image_objects = []\n",
    "        valid_paths_in_batch = []\n",
    "        for path in batch_paths:\n",
    "            image = self._load_image_for_batch(path)\n",
    "            if image:\n",
    "                batch_image_objects.append(image)\n",
    "                valid_paths_in_batch.append(path)\n",
    "            else:\n",
    "                self.stats['total_errors_pass2'] += 1\n",
    "        return valid_paths_in_batch, batch_image_objects\n",
    "\n",
    "    # --- Private Methods: Inference ---\n",
    "\n",
    "    def _run_object_detection_batch(self, model_pipeline, image_batch):\n",
    "        \"\"\"\n",
    "        Runs an object detection pipeline on a batch of images.\n",
    "        Returns a list of detection results (list of lists).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # The pipeline returns a list[list[dict]]\n",
    "            batch_results = model_pipeline(image_batch)\n",
    "            return batch_results\n",
    "        except Exception as e:\n",
    "            print(f\"   [Error] Object detection model failed: {e}\", file=sys.stderr)\n",
    "            raise  # Re-raise to be caught by the batch processor\n",
    "\n",
    "    def _run_zero_shot_batch(self, model_pipeline, image_batch, candidate_labels):\n",
    "        \"\"\"\n",
    "        Runs a zero-shot classifier on a batch of images.\n",
    "        Returns a list of classification results.\n",
    "        \"\"\"\n",
    "        # (This method is identical to v5's)\n",
    "        try:\n",
    "            batch_results = model_pipeline(image_batch, candidate_labels=candidate_labels)\n",
    "            return batch_results\n",
    "        except Exception as e:\n",
    "            print(f\"   [Error] Zero-shot model failed: {e}\", file=sys.stderr)\n",
    "            raise  # Re-raise to be caught by the batch processor\n",
    "\n",
    "    # --- Private Methods: Helpers & Reporting ---\n",
    "\n",
    "    def _calculate_hash(self, file_path):\n",
    "        \"\"\"Calculates the SHA256 hash of a file efficiently.\"\"\"\n",
    "        # (This method is identical to v5)\n",
    "        hasher = hashlib.sha256()\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                while chunk := f.read(self.HASH_CHUNK_SIZE):\n",
    "                    hasher.update(chunk)\n",
    "            return hasher.hexdigest()\n",
    "        except (IOError, OSError) as e:\n",
    "            print(f\"   [Warning] Could not hash file {file_path}: {e}\", file=sys.stderr)\n",
    "            return None\n",
    "\n",
    "    def _get_unique_dest_path(self, dest_dir, file_name):\n",
    "        \"\"\"\n",
    "        Checks if a file exists. If so, appends a counter\n",
    "        (e.g., '_1', '_2') until a unique name is found.\n",
    "        \"\"\"\n",
    "        # (This method is identical to v5)\n",
    "        dest_path = os.path.join(dest_dir, file_name)\n",
    "        if not os.path.exists(dest_path):\n",
    "            return dest_path\n",
    "\n",
    "        base, ext = os.path.splitext(file_name)\n",
    "        counter = 1\n",
    "        while True:\n",
    "            new_name = f\"{base}_{counter}{ext}\"\n",
    "            new_dest_path = os.path.join(dest_dir, new_name)\n",
    "            if not os.path.exists(new_dest_path):\n",
    "                return new_dest_path\n",
    "            counter += 1\n",
    "\n",
    "    @staticmethod\n",
    "    @contextmanager\n",
    "    def _suppress_pil_warnings():\n",
    "        \"\"\"Context manager to suppress known PIL warnings.\"\"\"\n",
    "        # (This method is identical to v5)\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            \"(Possibly corrupt EXIF data|Image size.*exceeds pixel limit)\"\n",
    "        )\n",
    "        yield\n",
    "        warnings.resetwarnings()\n",
    "\n",
    "    def _load_image_for_batch(self, path):\n",
    "        \"\"\"\n",
    "        Safely opens, converts, and loads one image.\n",
    "        Returns None if the image fails to load.\n",
    "        \"\"\"\n",
    "        # (This method is identical to v5)\n",
    "        try:\n",
    "            with self._suppress_pil_warnings(), Image.open(path) as image:\n",
    "                if image.mode == 'RGBA':\n",
    "                    image_rgb = image.convert('RGB')\n",
    "                else:\n",
    "                    image.load() # Must load to keep in memory\n",
    "                    image_rgb = image\n",
    "                return image_rgb\n",
    "        except Exception as e:\n",
    "            print(f\"   [Error] Failed to load {path}: {e}\", file=sys.stderr)\n",
    "            return None\n",
    "\n",
    "    def _print_final_report(self):\n",
    "        \"\"\"Prints a summary of all actions taken.\"\"\"\n",
    "        # (This method is identical to v5)\n",
    "        print(\"\\n--- Sorting Complete ---\")\n",
    "        print(f\"Total files scanned: {self.stats['total_files_scanned']}\")\n",
    "        print(f\"Duplicate files skipped: {self.stats['skipped_duplicates']}\")\n",
    "        print(f\"Unique files processed: {self.stats['processed_files_moved']}\")\n",
    "        \n",
    "        total_errors = self.stats['total_errors_pass1'] + self.stats['total_errors_pass2']\n",
    "        print(f\"Total errors: {total_errors}\")\n",
    "        \n",
    "        print(f\"\\nCheck the folders in: {self.output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ba1609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dependencies...\n",
      "HEIF/HEIC support enabled.\n",
      "All critical dependencies are present.\n",
      "--- AI Photo Sorter (v6) ---\n",
      "Source: D:\\images\\HockingHills\n",
      "Destination: D:\\images\\output\n",
      "Batch Size: 32\n",
      "-------------------------\n",
      "Setting up output directories...\n",
      "Output directories ready.\n",
      "Loading AI models... (This may take a few minutes and download files on first run)\n",
      "Loading Model 1: d-li/mobilefacedet (Face Detector)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\xiaom\\AppData\\Local\\Temp\\ipykernel_28624\\1740800452.py:9: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  source_folder = \"D:\\images\\HockingHills\"\n",
      "C:\\Users\\xiaom\\AppData\\Local\\Temp\\ipykernel_28624\\1740800452.py:10: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  output_folder = \"D:\\images\\output\"\n",
      "Error loading models: d-li/mobilefacedet is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
      "Please ensure you have an internet connection.\n",
      "\n",
      "--- [FATAL ERROR] ---\n",
      "An unexpected error occurred: d-li/mobilefacedet is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 409, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/d-li/mobilefacedet/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 424, in cached_files\n",
      "    hf_hub_download(\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 961, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1068, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1596, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1484, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1401, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 285, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 309, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 459, in hf_raise_for_status\n",
      "    raise _format(RepositoryNotFoundError, message, response) from e\n",
      "huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-6902fcc5-10329ddc67863df236b2a96a;10e448c5-0158-425c-9ad0-761015366a1f)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/d-li/mobilefacedet/resolve/main/config.json.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\n",
      "Invalid username or password.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xiaom\\AppData\\Local\\Temp\\ipykernel_28624\\637286988.py\", line 155, in run_sort\n",
      "    self._load_models()\n",
      "  File \"C:\\Users\\xiaom\\AppData\\Local\\Temp\\ipykernel_28624\\637286988.py\", line 181, in _load_models\n",
      "    self.face_detector_pipeline = pipeline(\n",
      "                                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\pipelines\\__init__.py\", line 812, in pipeline\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 266, in cached_file\n",
      "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 456, in cached_files\n",
      "    raise OSError(\n",
      "OSError: d-li/mobilefacedet is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n"
     ]
    }
   ],
   "source": [
    "# --- Main execution ---\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the script.\n",
    "    Set your source and output folders here.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- CONFIGURE YOUR PATHS HERE ---\n",
    "    source_folder = \"D:\\images\\HockingHills\"\n",
    "    output_folder = \"D:\\images\\output\"\n",
    "    # --- END CONFIGURATION ---\n",
    "\n",
    "    \n",
    "    # Check if the user has updated the default paths\n",
    "    if \"C:\\\\path\\\\to\" in source_folder:\n",
    "        print(\"Error: Please update the 'source_folder' and 'output_folder' variables\", file=sys.stderr)\n",
    "        print(\"inside the main() function at the bottom of the script.\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    if not os.path.isdir(source_folder):\n",
    "        print(f\"Error: Source folder not found: {source_folder}\", file=sys.stderr)\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # 1. Check dependencies first\n",
    "        AIPhotoSorter.check_dependencies()\n",
    "        \n",
    "        # 2. Create and run the sorter instance\n",
    "        sorter = AIPhotoSorter(source_folder, output_folder, batch_size=32)\n",
    "        sorter.run_sort()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- [FATAL ERROR] ---\", file=sys.stderr)\n",
    "        print(f\"An unexpected error occurred during setup: {e}\", file=sys.stderr)\n",
    "        traceback.print_exc(file=sys.stderr)\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
