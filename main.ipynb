{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEIC/HEIF support enabled.\n",
      "Warning: FaceAnalysis not installed.\n",
      "pip install insightface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import shutil\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Generator, Any\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# --- HEIC/HEIF Support ---\n",
    "# This is required to make PIL.Image.open() support HEIC/HEIF formats.\n",
    "# You must install this library: pip install pillow-heif\n",
    "try:\n",
    "    import pillow_heif\n",
    "    pillow_heif.register_heif_opener()\n",
    "    print(\"HEIC/HEIF support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: 'pillow-heif' not installed. HEIC/HEIF files will be skipped.\")\n",
    "    print(\"Install with: pip install pillow-heif\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "try:\n",
    "    from insightface.app import FaceAnalysis\n",
    "    print(\"FaceAnalysis support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: FaceAnalysis not installed.\")\n",
    "    print(\"pip install insightface\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "# --- Hugging Face transformers ---\n",
    "# You must install this library: pip install transformers torch\n",
    "try:\n",
    "    from transformers import pipeline, Pipeline\n",
    "    from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"CRITICAL: 'transformers' or 'torch' not found.\")\n",
    "    print(\"Please install them to run this script: pip install transformers torch\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "class ImageDataloader:\n",
    "    \"\"\"\n",
    "    Scans a directory for unique images and provides batches for processing.\n",
    "\n",
    "    This class is implemented as a Python generator. It does not\n",
    "    inherit from torch.utils.data.DataLoader, as our use case\n",
    "    requires a simple, stateful iterator.\n",
    "    \"\"\"\n",
    "    IMAGE_EXTENSIONS: tuple = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "\n",
    "    def __init__(self, root_dir: str, batch_size: int = 32):\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"Root directory not found: {root_dir}\")\n",
    "        if batch_size <= 0:\n",
    "            raise ValueError(\"Batch size must be greater than 0\")\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.labels will hold the \"working state\" of all images\n",
    "        # {image_path: \"unknown\"}\n",
    "        self.labels: Dict[str, str] = {}\n",
    "        self._scan_and_deduplicate()\n",
    "\n",
    "    def _calculate_hash(self, filepath: str, block_size: int = 65536) -> str:\n",
    "        \"\"\"\n",
    "        Calculates the SHA256 hash of a file's content.\n",
    "        \"\"\"\n",
    "        sha256 = hashlib.sha256()\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                while chunk := f.read(block_size):\n",
    "                    sha256.update(chunk)\n",
    "            return sha256.hexdigest()\n",
    "        except (IOError, OSError) as e:\n",
    "            print(f\"Warning: Could not read file for hashing: {filepath}. Skipping. Error: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _scan_and_deduplicate(self):\n",
    "        \"\"\"\n",
    "        Walks the root directory, finds all unique images, and\n",
    "        populates self.labels with the default 'unknown' label.\n",
    "        \"\"\"\n",
    "        print(f\"Scanning directory: {self.root_dir}...\")\n",
    "        image_hashes: set[str] = set()\n",
    "        total_files = 0\n",
    "        duplicates_skipped = 0\n",
    "\n",
    "        for root, _, files in os.walk(self.root_dir):\n",
    "            for file in files:\n",
    "                if not file.lower().endswith(self.IMAGE_EXTENSIONS):\n",
    "                    continue\n",
    "\n",
    "                total_files += 1\n",
    "                full_path = os.path.join(root, file)\n",
    "                file_hash = self._calculate_hash(full_path)\n",
    "\n",
    "                if not file_hash:\n",
    "                    continue\n",
    "\n",
    "                if file_hash not in image_hashes:\n",
    "                    image_hashes.add(file_hash)\n",
    "                    # All images start as 'unknown'\n",
    "                    self.labels[full_path] = \"unknown\"\n",
    "                else:\n",
    "                    duplicates_skipped += 1\n",
    "\n",
    "        print(\"--- Scan Complete ---\")\n",
    "        print(f\"Total image files found: {total_files}\")\n",
    "        print(f\"Duplicate images skipped: {duplicates_skipped}\")\n",
    "        print(f\"Total unique images to process: {len(self.labels)}\")\n",
    "        if not self.labels:\n",
    "            print(\"Warning: No valid, unique images were found.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of unique images to be processed.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __iter__(self) -> Generator[Dict[str, str], None, None]:\n",
    "        \"\"\"\n",
    "        Yields batches of images as dictionaries {image_path: label}.\n",
    "        \"\"\"\n",
    "        # Get a static list of paths to iterate over\n",
    "        all_paths = list(self.labels.keys())\n",
    "        \n",
    "        for i in range(0, len(all_paths), self.batch_size):\n",
    "            batch_paths = all_paths[i : i + self.batch_size]\n",
    "            \n",
    "            # Create the batch dict\n",
    "            batch_data = {path: self.labels[path] for path in batch_paths}\n",
    "            \n",
    "            if batch_data:\n",
    "                yield batch_data\n",
    "\n",
    "\n",
    "class ImageClassifier:\n",
    "    \"\"\"\n",
    "    Uses a \"waterfall\" method to classify images from a dataloader\n",
    "    using multiple, chained AI models.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader: ImageDataloader, output_dir: str = \"output\"):\n",
    "        self.dataloader = dataloader\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # 1. Determine the device\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.pipeline_device = 0 if self.device == torch.device('cuda') else -1\n",
    "        print(f\"Using device: {self.device} (Pipeline device: {self.pipeline_device})\")\n",
    "        \n",
    "        self.output_paths = {\n",
    "            \"people\": os.path.join(output_dir, \"people\"),\n",
    "            \"view\": os.path.join(output_dir, \"view\"),\n",
    "            \"unknown\": os.path.join(output_dir, \"unknown\")\n",
    "        }\n",
    "        self._create_output_dirs()\n",
    "        \n",
    "        # --- Load Models in __init__ ---\n",
    "        print(\"Loading models...\")\n",
    "        \n",
    "        # Load retinaface_model \n",
    "        self.retinaface_model = self.load_retinaface_model()\n",
    "\n",
    "        # load detr model\n",
    "        self.detr_pipeline = self.load_detr_pipeline()\n",
    "\n",
    "        # Model 1: Face Detector (Pipeline)\n",
    "        try:\n",
    "            self.mobilefacedet_pipeline = pipeline(\n",
    "                \"object-detection\",\n",
    "                model=\"d-li/mobilefacedet\",\n",
    "                device=self.pipeline_device\n",
    "            )\n",
    "            print(\"Loaded: d-li/mobilefacedet\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load mobilefacedet. {e}\")\n",
    "            self.mobilefacedet_pipeline = None\n",
    "\n",
    "        # Model 2: CLIP (Pipeline)\n",
    "        try:\n",
    "            self.clip_pipeline = pipeline(\n",
    "                \"zero-shot-image-classification\",\n",
    "                model=\"openai/clip-vit-large-patch14\",\n",
    "                device=self.pipeline_device\n",
    "            )\n",
    "            print(\"Loaded: clip-vit-large-patch14\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load CLIP. {e}\")\n",
    "            self.clip_pipeline = None\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        print(\"Model loading complete.\")\n",
    "\n",
    "\n",
    "    # --- Specific retinaface Model ---\n",
    "\n",
    "    def load_retinaface_model(self):\n",
    "        app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "        app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "        return app\n",
    "\n",
    "    def detect_with_RetinaFace(self, batch_data, model):\n",
    "        \"\"\"\n",
    "        batch_data: dict {image_path: label}\n",
    "        model: RetinaFace model (insightface FaceAnalysis)\n",
    "\n",
    "        Processes only images labeled 'unknown'.\n",
    "        Returns updated batch_data with detections.\n",
    "        \"\"\"\n",
    "        updated_data = batch_data.copy()\n",
    "\n",
    "        # 1️⃣ Filter for unknown images\n",
    "        unknown_items = [(path, label) for path, label in batch_data.items() if label == \"unknown\"]\n",
    "        if not unknown_items:\n",
    "            return updated_data\n",
    "\n",
    "        image_paths = [p for p, _ in unknown_items]\n",
    "\n",
    "        # 2️⃣ Load all images once\n",
    "        loaded_images = {}\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_bgr = np.array(img)[:, :, ::-1]  # RGB → BGR\n",
    "                loaded_images[img_path] = img_bgr\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error reading {img_path}: {e}\")\n",
    "                updated_data[img_path] = \"invalid\"\n",
    "\n",
    "        # 3️⃣ Run inference per image (insightface doesn't support batch)\n",
    "        for img_path, img_bgr in loaded_images.items():\n",
    "            faces = model.get(img_bgr)  # must be called one by one\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                updated_data[img_path] = \"people\"\n",
    "\n",
    "        return updated_data\n",
    "\n",
    "\n",
    "    # --- Specific detr Model ---\n",
    "    def load_detr_pipeline(self):\n",
    "        try:\n",
    "            model = \"facebook/detr-resnet-50\"\n",
    "            detr_pipeline = pipeline(\"object-detection\", model=model, device=self.pipeline_device)\n",
    "            print(\"Loaded: facebook/detr-resnet-50\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load DETR. {e}\")\n",
    "            detr_pipeline = None\n",
    "        return detr_pipeline\n",
    "\n",
    "\n",
    "    def detect_human_detr_pipeline(batch_data: Dict[str, str], detr_pipeline: Any) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Detects humans ('person' label) in ALL images labeled 'unknown' using the \n",
    "        Hugging Face pipeline in a single batch operation and updates the labels.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            detr_pipeline (transformers.Pipeline): The loaded DETR object detection pipeline.\n",
    "            confidence_threshold (float): Minimum confidence for a detection to be considered.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        # DETR is trained on COCO, where the label for a human is 'person'\n",
    "        PERSON_LABEL = 'person' \n",
    "        confidence_threshold = 0.9\n",
    "\n",
    "        if detr_pipeline is None:\n",
    "            print(\"ERROR: Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        print(f\"\\nProcessing all {len(unknown_paths)} 'unknown' images using the pipeline...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # The pipeline handles moving data to the device defined during load.\n",
    "        # We pass the list of PIL images directly.\n",
    "        try:\n",
    "            # The result is a list of lists: [[det1, det2, ...], [det1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = detr_pipeline(batch_images)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 3. Post-process the results\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            is_human_detected = False\n",
    "            \n",
    "            # image_results is a list of dictionaries (one for each detection)\n",
    "            for detection in image_results:\n",
    "                # The pipeline provides the score and the label (e.g., 'person')\n",
    "                if detection['score'] >= confidence_threshold and detection['label'] == PERSON_LABEL:\n",
    "                    is_human_detected = True\n",
    "                    # print(f\"✅ Detected {PERSON_LABEL} in: {image_path} with score {detection['score']:.2f}\")\n",
    "                    break # Found a person, no need to check other detections for this image\n",
    "\n",
    "            if is_human_detected:\n",
    "                batch_data[image_path] = 'people'\n",
    "\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using the pipeline.\")\n",
    "        return batch_data\n",
    "\n",
    "\n",
    "    def _create_output_dirs(self):\n",
    "        \"\"\"Creates the output directories if they don't exist.\"\"\"\n",
    "        print(f\"Ensuring output directories exist at: {self.output_dir}\")\n",
    "        for path in self.output_paths.values():\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    def _move_file(self, image_path: str, new_label: str):\n",
    "        \"\"\"Moves a file to its new classified directory.\"\"\"\n",
    "        if new_label not in self.output_paths:\n",
    "            print(f\"Warning: Unknown label '{new_label}'. Cannot move file.\")\n",
    "            return\n",
    "\n",
    "        target_dir = self.output_paths[new_label]\n",
    "        filename = os.path.basename(image_path)\n",
    "        target_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        i = 1\n",
    "        while os.path.exists(target_path):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            target_path = os.path.join(target_dir, f\"{name}_{i}{ext}\")\n",
    "            i += 1\n",
    "            \n",
    "        try:\n",
    "            shutil.move(image_path, target_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file {image_path} to {target_path}. Error: {e}\")\n",
    "\n",
    "    def classify_images(self):\n",
    "        \"\"\"\n",
    "        The main classification loop (orchestrator).\n",
    "        Iterates through all batches and applies the waterfall logic.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Starting Image Classification Waterfall ---\")\n",
    "        total_batches = (len(self.dataloader) + self.dataloader.batch_size - 1) // self.dataloader.batch_size\n",
    "        \n",
    "        for i, initial_batch in enumerate(self.dataloader):\n",
    "            print(f\"\\nProcessing Batch {i+1} / {total_batches} (Size: {len(initial_batch)})...\")\n",
    "            \n",
    "            remaining_batch = initial_batch.copy()\n",
    "\n",
    "            # --- STAGE 1: Detect faces ---\n",
    "            remaining_batch = self.detect_human_detr_pipeline(remaining_batch, self.retinaface_model)\n",
    "            # --- STAGE 1: Detect people ---\n",
    "            remaining_batch = self.detect_with_RetinaFace(remaining_batch, self.retinaface_model)\n",
    "\n",
    "            \n",
    "            # --- STAGE 2: View Models ---\n",
    "            if self.clip_pipeline:\n",
    "                remaining_batch = self.classify_with_clip(\n",
    "                    remaining_batch, self.clip_pipeline,\n",
    "                    target_label=\"view\",\n",
    "                    prompts=[\"a photo of a landscape\", \"a beautiful view\", \"a flower\", \"a photo of food\", \"a city skyline\", \"a beach\", \"mountains\", \"a forest\"]\n",
    "                )\n",
    "\n",
    "            if self.detr_pipeline:\n",
    "                remaining_batch = self.classify_with_detr(\n",
    "                    remaining_batch, self.detr_pipeline,\n",
    "                    target_label=\"view\",\n",
    "                    target_classes={\"flower\", \"bird\", \"cat\", \"dog\", \"horse\", \"pizza\", \"donut\", \"cake\", \"boat\", \"airplane\", \"bench\", \"car\", \"bus\"}\n",
    "                )\n",
    "\n",
    "            # --- STAGE 3: Custom Models (Example) ---\n",
    "            # if self.my_custom_model:\n",
    "            #     remaining_batch = self.classify_with_custom_model(remaining_batch, self.my_custom_model)\n",
    "\n",
    "            # --- STAGE 4: unknown ---\n",
    "            print(f\"Moving {len(remaining_batch)} remaining images to 'unknown'...\")\n",
    "            for path in remaining_batch.keys():\n",
    "                self._move_file(path, \"unknown\")\n",
    "                \n",
    "            print(f\"Batch {i+1} complete.\")\n",
    "\n",
    "        print(\"\\n--- Image Classification Finished ---\")\n",
    "\n",
    "    # --- Specific Model Classification Methods ---\n",
    "\n",
    "\n",
    "\n",
    "    def classify_with_mobilefacedet(self, batch_data: Dict[str, str], model: Pipeline) -> Dict[str, str]:\n",
    "        \"\"\"Runs the mobilefacedet pipeline.\"\"\"\n",
    "        if not batch_data: return {}\n",
    "            \n",
    "        print(f\"  Running 'mobilefacedet' on {len(batch_data)} images...\")\n",
    "        paths = list(batch_data.keys())\n",
    "        \n",
    "        try:\n",
    "            results = model(paths, batch_size=self.dataloader.batch_size)\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR: Model 'mobilefacedet' failed. {e}\")\n",
    "            return batch_data\n",
    "\n",
    "        remaining_batch = batch_data.copy()\n",
    "        moved_count = 0\n",
    "        for path, result_list in zip(paths, results):\n",
    "            if result_list: # Found a face\n",
    "                self._move_file(path, \"people\")\n",
    "                del remaining_batch[path]\n",
    "                moved_count += 1\n",
    "                \n",
    "        print(f\"    Moved {moved_count} images to 'people'.\")\n",
    "        return remaining_batch\n",
    "\n",
    "    def classify_with_clip(self, batch_data: Dict[str, str], model: Pipeline, target_label: str, prompts: List[str]) -> Dict[str, str]:\n",
    "        \"\"\"Runs the CLIP zero-shot pipeline.\"\"\"\n",
    "        if not batch_data: return {}\n",
    "\n",
    "        print(f\"  Running 'CLIP' for '{target_label}' on {len(batch_data)} images...\")\n",
    "        paths = list(batch_data.keys())\n",
    "\n",
    "        try:\n",
    "            results = model(paths, candidate_labels=prompts, batch_size=self.dataloader.batch_size)\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR: Model 'CLIP' failed. {e}\")\n",
    "            return batch_data\n",
    "\n",
    "        remaining_batch = batch_data.copy()\n",
    "        moved_count = 0\n",
    "        for path, result_list in zip(paths, results):\n",
    "            top_label = result_list[0]['label']\n",
    "            top_score = result_list[0]['score']\n",
    "\n",
    "            if top_label in prompts and top_score > 0.8: # Confidence threshold\n",
    "                self._move_file(path, target_label)\n",
    "                del remaining_batch[path]\n",
    "                moved_count += 1\n",
    "        \n",
    "        print(f\"    Moved {moved_count} images to '{target_label}'.\")\n",
    "        return remaining_batch\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b7d38c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: D:\\images\\HockingHills...\n",
      "--- Scan Complete ---\n",
      "Total image files found: 91\n",
      "Duplicate images skipped: 0\n",
      "Total unique images to process: 91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dir = r\"D:\\images\\HockingHills\"\n",
    "output = r\"D:\\images\\output\"\n",
    "\n",
    "# 1. Instantiate the Dataloader\n",
    "# Using a small batch size for the example\n",
    "dataloader = ImageDataloader(root_dir=test_dir, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for batch in dataloader:\n",
    "#     # 2. Run the detection\n",
    "#     result = detect_human_batch(batch.copy(), processor, model)\n",
    "\n",
    "\n",
    "# for key in batch:\n",
    "#     print(key, batch[key], result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run the classification\n",
    "# This will use the *actual* AI models on the dummy images.\n",
    "# The dummy images won't be classified correctly, but this\n",
    "# demonstrates the file scanning, de-duplication, batching,\n",
    "# model loading, and file moving logic.\n",
    "try:\n",
    "    classifier.classify_images()\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during classification: {e}\")\n",
    "    print(\"This can happen if you are offline or models are unavailable.\")\n",
    "\n",
    "# 5. Print a summary\n",
    "print(\"\\n--- Final Output Summary ---\")\n",
    "try:\n",
    "    for category in os.listdir(output):\n",
    "        category_path = os.path.join(output, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            files = os.listdir(category_path)\n",
    "            print(f\"Files in '{category}': {len(files)} {files}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Output directory 'classification_output' not found. Did the script run?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
