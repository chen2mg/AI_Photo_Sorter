{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9cd70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "AI Photo Sorter (v3)\n",
    "Sorts a directory of images using a two-stage \"waterfall\" classification\n",
    "and proper, fixed-size batching for memory safety and performance.\n",
    "\n",
    "This version corrects a major flaw from v2 and is safe to run on\n",
    "very large photo libraries (e.g., 20,000+ images) without\n",
    "crashing due to \"Out of Memory\" errors.\n",
    "\n",
    "REQUIREMENTS:\n",
    "pip install torch transformers Pillow pillow-heif\n",
    "\n",
    "--- USAGE IN JUPYTER NOTEBOOK ---\n",
    "1. Make sure you have run: !pip install torch transformers Pillow pillow-heif\n",
    "2. Define your paths in a notebook cell:\n",
    "\n",
    "   source_folder = r\"C:\\path\\to\\your\\iphone_photos_copy\"\n",
    "   output_folder = r\"C:\\path\\to\\my_sorted_photos\"\n",
    "\n",
    "3. Call the function in the next cell:\n",
    "\n",
    "   if 'source_folder' in locals() and os.path.isdir(source_folder):\n",
    "       sort_images(source_folder, output_folder)\n",
    "   else:\n",
    "       print(\"Please define 'source_folder' and 'output_folder' in your notebook cell.\")\n",
    "       print(\"See the docstring at the top of this file for an example.\")\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import hashlib\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# --- Dependency Checking ---\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    print(\"Error: 'Pillow' library not found. Please install with: pip install Pillow\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"Error: 'torch' library not found. Please install with: pip install torch\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "except ImportError:\n",
    "    print(\"Error: 'transformers' library not found. Please install with: pip install transformers\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    import pillow_heif\n",
    "    # Register the HEIF plugin with PIL\n",
    "    pillow_heif.register_heif_opener()\n",
    "except ImportError:\n",
    "    print(\"Warning: 'pillow-heif' library not found. HEIC/HEIF files will not be processed.\", file=sys.stderr)\n",
    "    print(\"Install with: pip install pillow-heif\", file=sys.stderr)\n",
    "\n",
    "\n",
    "# --- Constants ---\n",
    "\n",
    "# --- NEW: BATCH_SIZE ---\n",
    "# This is the number of images to load into memory and process at a time.\n",
    "# - Increase (e.g., 64, 128) if you have a powerful GPU with lots of VRAM.\n",
    "# - Decrease (e.g., 16, 8) if you get \"Out of Memory\" errors or have an older GPU.\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# The AI model will categorize images based on these text labels.\n",
    "CATEGORIES = [\n",
    "    \"a photo of a person, face, or family\",\n",
    "    \"a scenic landscape, mountain, beach, or flower\",\n",
    "    \"a photo of delicious food or a meal\",\n",
    "    \"a screenshot of a phone or computer screen\",\n",
    "    \"a photo of a receipt, document, or white-board\",\n",
    "    \"a graphic, logo, or drawing\",\n",
    "    \"a blurry or dark photo\"\n",
    "]\n",
    "\n",
    "# Mapping from the AI's category label to our destination folder names\n",
    "CATEGORY_TO_FOLDER = {\n",
    "    \"a photo of a person, face, or family\": \"family_photos\",\n",
    "    \"a scenic landscape, mountain, beach, or flower\": \"views\",\n",
    "    \"a photo of delicious food or a meal\": \"views\",\n",
    "    \"a screenshot of a phone or computer screen\": \"junk\",\n",
    "    \"a photo of a receipt, document, or white-board\": \"junk\",\n",
    "    \"a graphic, logo, or drawing\": \"junk\",\n",
    "    \"a blurry or dark photo\": \"junk\"\n",
    "}\n",
    "\n",
    "# --- Constants for 2nd Model (Object Detection) ---\n",
    "# ... (same as v2) ...\n",
    "OBJECT_DETECTOR_PERSON_LABELS = {'person'}\n",
    "OBJECT_DETECTOR_PERSON_THRESHOLD = 0.8  # Be pretty confident it's a person\n",
    "OBJECT_DETECTOR_VIEW_LABELS = {\n",
    "    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'dining table', 'bowl', 'cup', 'fork', 'knife', 'spoon',\n",
    "    'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "    'parking meter', 'bench', 'motorcycle', 'bicycle',\n",
    "    'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'frisbee'\n",
    "}\n",
    "OBJECT_DETECTOR_VIEW_THRESHOLD = 0.7 # Moderately confident\n",
    "\n",
    "IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "HASH_CHUNK_SIZE = 8192  # Read files in 8KB chunks for hashing\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def calculate_hash(file_path):\n",
    "    \"\"\"Calculates the SHA256 hash of a file efficiently.\"\"\"\n",
    "    hasher = hashlib.sha256()\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            while chunk := f.read(HASH_CHUNK_SIZE):\n",
    "                hasher.update(chunk)\n",
    "        return hasher.hexdigest()\n",
    "    except (IOError, OSError) as e:\n",
    "        print(f\"  [Warning] Could not hash file {file_path}: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "def get_unique_dest_path(dest_dir, file_name):\n",
    "    \"\"\"\n",
    "    Checks if a file exists at the destination. If so, appends\n",
    "    a counter (e.g., '_1', '_2') until a unique name is found.\n",
    "    \"\"\"\n",
    "    dest_path = os.path.join(dest_dir, file_name)\n",
    "    \n",
    "    if not os.path.exists(dest_path):\n",
    "        return dest_path\n",
    "\n",
    "    # Handle collision\n",
    "    base, ext = os.path.splitext(file_name)\n",
    "    counter = 1\n",
    "    while True:\n",
    "        new_name = f\"{base}_{counter}{ext}\"\n",
    "        new_dest_path = os.path.join(dest_dir, new_name)\n",
    "        if not os.path.exists(new_dest_path):\n",
    "            return new_dest_path\n",
    "        counter += 1\n",
    "\n",
    "@contextmanager\n",
    "def suppress_pil_warnings():\n",
    "    \"\"\"Context manager to suppress known PIL warnings like 'Possibly corrupt EXIF data'.\"\"\"\n",
    "    import warnings\n",
    "    from PIL import Image\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\",\n",
    "        \"(Possibly corrupt EXIF data|Image size.*exceeds pixel limit)\"\n",
    "    )\n",
    "    yield\n",
    "    warnings.resetwarnings()\n",
    "\n",
    "def load_image_for_batch(path):\n",
    "    \"\"\"\n",
    "    Safely opens, converts, and loads one image.\n",
    "    Returns None if the image fails to load.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with suppress_pil_warnings(), Image.open(path) as image:\n",
    "            if image.mode == 'RGBA':\n",
    "                image_rgb = image.convert('RGB')\n",
    "            else:\n",
    "                image.load() # Must load to keep in memory\n",
    "                image_rgb = image\n",
    "            return image_rgb\n",
    "    except Exception as e:\n",
    "        print(f\"  [Error] Failed to load {path}: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "# --- Main Function ---\n",
    "\n",
    "def sort_images(root_path, output_path):\n",
    "    \"\"\"\n",
    "    Recursively scans the root_path, classifies images, and moves them\n",
    "    to the output_path, sorted into subdirectories.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Setup Output Directories\n",
    "    output_dirs = {\n",
    "        \"family_photos\": os.path.join(output_path, \"family_photos\"),\n",
    "        \"views\": os.path.join(output_path, \"views\"),\n",
    "        \"junk\": os.path.join(output_path, \"junk\")\n",
    "    }\n",
    "\n",
    "    for dir_path in output_dirs.values():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    print(\"--- AI Photo Sorter (v3) ---\")\n",
    "    print(f\"Source: {root_path}\")\n",
    "    print(f\"Destination: {output_path}\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    # 2. Load AI Models\n",
    "    print(\"Loading AI models... (This may take a few minutes and download files on first run)\")\n",
    "    try:\n",
    "        device = 0 if torch.cuda.is_available() else -1\n",
    "        \n",
    "        print(\"Loading Model 1: Zero-Shot Classifier (openai/clip-vit-large-patch14)...\")\n",
    "        classifier = pipeline(\n",
    "            \"zero-shot-image-classification\",\n",
    "            model=\"openai/clip-vit-large-patch14\",\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        print(\"Loading Model 2: Object Detector (facebook/detr-resnet-50)...\")\n",
    "        detector = pipeline(\n",
    "            \"object-detection\",\n",
    "            model=\"facebook/detr-resnet-50\",\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        print(\"Models loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {e}\", file=sys.stderr)\n",
    "        print(\"Please ensure you have an internet connection and 'transformers' and 'torch' are installed.\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # --- NEW: Pass 1: Pre-scan for duplicates and build master file list ---\n",
    "    print(\"\\n--- Pass 1: Scanning for duplicates and building file list ---\")\n",
    "    \n",
    "    seen_hashes = {}  # { 'hash_value': 'path_to_first_file_seen' }\n",
    "    unique_image_paths = [] # Master list of paths to process\n",
    "    total_files_scanned = 0\n",
    "    skipped_duplicates = 0\n",
    "    total_errors_pass1 = 0\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(root_path):\n",
    "        print(f\"Scanning: {dirpath}\")\n",
    "        for filename in filenames:\n",
    "            if not filename.lower().endswith(IMAGE_EXTENSIONS):\n",
    "                continue\n",
    "            \n",
    "            total_files_scanned += 1\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "\n",
    "            file_hash = calculate_hash(full_path)\n",
    "            if not file_hash:\n",
    "                total_errors_pass1 += 1\n",
    "                continue  # Skip if hashing failed\n",
    "\n",
    "            if file_hash in seen_hashes:\n",
    "                print(f\"  -> Duplicate of: {seen_hashes[file_hash]} (Skipping)\")\n",
    "                skipped_duplicates += 1\n",
    "                continue\n",
    "            else:\n",
    "                seen_hashes[file_hash] = full_path\n",
    "                unique_image_paths.append(full_path) # Add to our master list\n",
    "\n",
    "    print(f\"\\n--- Pass 1 Complete ---\")\n",
    "    print(f\"Total files scanned: {total_files_scanned}\")\n",
    "    print(f\"Duplicate files found: {skipped_duplicates}\")\n",
    "    print(f\"Unique images to process: {len(unique_image_paths)}\")\n",
    "    print(f\"Hashing/Read errors: {total_errors_pass1}\")\n",
    "\n",
    "\n",
    "    # --- NEW: Pass 2: Process unique images in fixed-size batches ---\n",
    "    print(\"\\n--- Pass 2: Processing unique images in batches ---\")\n",
    "    \n",
    "    processed_files_moved = 0\n",
    "    total_errors_pass2 = 0\n",
    "    num_batches = (len(unique_image_paths) + BATCH_SIZE - 1) // BATCH_SIZE # Calculate total batches\n",
    "\n",
    "    for i in range(0, len(unique_image_paths), BATCH_SIZE):\n",
    "        \n",
    "        # Get the paths for this one batch\n",
    "        batch_paths = unique_image_paths[i : i + BATCH_SIZE]\n",
    "        \n",
    "        print(f\"\\nProcessing Batch {i//BATCH_SIZE + 1} / {num_batches} (Size: {len(batch_paths)})...\")\n",
    "\n",
    "        # Load image objects for this batch\n",
    "        batch_image_objects = []\n",
    "        # Keep track of paths, as some images might fail to load\n",
    "        valid_paths_in_batch = [] \n",
    "        \n",
    "        for path in batch_paths:\n",
    "            image = load_image_for_batch(path)\n",
    "            if image:\n",
    "                batch_image_objects.append(image)\n",
    "                valid_paths_in_batch.append(path)\n",
    "            else:\n",
    "                total_errors_pass2 += 1\n",
    "        \n",
    "        if not batch_image_objects:\n",
    "            print(\"  -> All images in batch failed to load. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # C) Classify Batch with Model 1 (CLIP)\n",
    "            print(f\"  Running Model 1 (Zero-Shot) on {len(batch_image_objects)} images...\")\n",
    "            batch_clip_results = classifier(batch_image_objects, candidate_labels=CATEGORIES)\n",
    "\n",
    "            # D) Check \"junk\" with Model 2 (DETR)\n",
    "            # Find which images Model 1 flagged as junk\n",
    "            junk_indices = [\n",
    "                idx for idx, result in enumerate(batch_clip_results)\n",
    "                if CATEGORY_TO_FOLDER.get(result[0]['label'], \"junk\") == \"junk\"\n",
    "            ]\n",
    "            \n",
    "            junk_images_to_check = [batch_image_objects[idx] for idx in junk_indices]\n",
    "            batch_detr_results = {} # Will store {index: [results]}\n",
    "            \n",
    "            if junk_images_to_check:\n",
    "                print(f\"  Running Model 2 (Object Detector) on {len(junk_images_to_check)} 'junk' candidates...\")\n",
    "                # Run detection on all junk candidates at once\n",
    "                detr_results_list = detector(junk_images_to_check)\n",
    "                \n",
    "                # Map results back to their original batch index\n",
    "                for j, detr_result in enumerate(detr_results_list):\n",
    "                    original_batch_index = junk_indices[j]\n",
    "                    batch_detr_results[original_batch_index] = detr_result\n",
    "            \n",
    "\n",
    "            # E) Iterate over batch results, decide destination, and move files\n",
    "            print(\"  Categorizing and moving files...\")\n",
    "            for j in range(len(valid_paths_in_batch)):\n",
    "                full_path = valid_paths_in_batch[j]\n",
    "                original_filename = os.path.basename(full_path)\n",
    "                clip_results = batch_clip_results[j]\n",
    "                \n",
    "                top_label = clip_results[0]['label']\n",
    "                dest_folder_name = CATEGORY_TO_FOLDER.get(top_label, \"junk\")\n",
    "\n",
    "                if dest_folder_name == \"junk\":\n",
    "                    # This image was in the junk pile, check Model 2's results\n",
    "                    objects = batch_detr_results.get(j, []) # Get results, or empty list\n",
    "                    \n",
    "                    found_person = False\n",
    "                    found_view_object = None\n",
    "                    \n",
    "                    for obj in objects:\n",
    "                        if obj['label'] in OBJECT_DETECTOR_PERSON_LABELS and obj['score'] > OBJECT_DETECTOR_PERSON_THRESHOLD:\n",
    "                            found_person = True\n",
    "                            break\n",
    "                        if obj['label'] in OBJECT_DETECTOR_VIEW_LABELS and obj['score'] > OBJECT_DETECTOR_VIEW_THRESHOLD:\n",
    "                            found_view_object = obj['label']\n",
    "                    \n",
    "                    if found_person:\n",
    "                        dest_folder_name = \"family_photos\"\n",
    "                    elif found_view_object:\n",
    "                        dest_folder_name = \"views\"\n",
    "\n",
    "                # F) Handle Filename Collisions and Move\n",
    "                dest_dir = output_dirs[dest_folder_name]\n",
    "                dest_path = get_unique_dest_path(dest_dir, original_filename)\n",
    "                \n",
    "                shutil.move(full_path, dest_path)\n",
    "                print(f\"    -> Moved {original_filename} to {dest_folder_name}\")\n",
    "                processed_files_moved += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  [CRITICAL BATCH ERROR] Failed to process batch {i//BATCH_SIZE + 1}: {e}\", file=sys.stderr)\n",
    "            print(\"    -> Skipping this entire batch. These files will not be moved.\", file=sys.stderr)\n",
    "            total_errors_pass2 += len(valid_paths_in_batch)\n",
    "            \n",
    "        # Clear memory (Python's garbage collector will handle this,\n",
    "        # but being explicit isn't bad)\n",
    "        del batch_image_objects\n",
    "        del valid_paths_in_batch\n",
    "        del batch_clip_results\n",
    "        del batch_detr_results\n",
    "\n",
    "\n",
    "    # 5. Final Report\n",
    "    print(\"\\n--- Sorting Complete ---\")\n",
    "    print(f\"Total files scanned: {total_files_scanned}\")\n",
    "    print(f\"Duplicate files skipped: {skipped_duplicates}\")\n",
    "    print(f\"Unique files processed: {processed_files_moved}\")\n",
    "    print(f\"Total errors (Pass 1 + Pass 2): {total_errors_pass1 + total_errors_pass2}\")\n",
    "    print(f\"\\nCheck the folders in: {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXAMPLE USAGE IN JUPYTER NOTEBOOK ---\n",
    "# 1. Make sure you have run: !pip install torch transformers Pillow pillow-heif\n",
    "# 2. Define your paths in a notebook cell:\n",
    "#\n",
    "source_folder = \"images\"\n",
    "output_folder = \"output\"\n",
    "#\n",
    "# 3. Call the function in the next cell:\n",
    "#\n",
    "if 'source_folder' in locals() and os.path.isdir(source_folder):\n",
    "    print(\"Starting photo sort...\")\n",
    "    sort_images(source_folder, output_folder)\n",
    "else:\n",
    "    print(\"Please define 'source_folder' and 'output_folder' in your notebook cell.\")\n",
    "    print(\"See the docstring at the top of this file for an example.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
