{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaom\\.conda\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEIC/HEIF support enabled.\n",
      "FaceAnalysis support enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import shutil\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Generator, Any\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter  \n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "# --- HEIC/HEIF Support ---\n",
    "# This is required to make PIL.Image.open() support HEIC/HEIF formats.\n",
    "# You must install this library: pip install pillow-heif\n",
    "try:\n",
    "    import pillow_heif\n",
    "    pillow_heif.register_heif_opener()\n",
    "    print(\"HEIC/HEIF support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: 'pillow-heif' not installed. HEIC/HEIF files will be skipped.\")\n",
    "    print(\"Install with: pip install pillow-heif\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "try:\n",
    "    from insightface.app import FaceAnalysis\n",
    "    print(\"FaceAnalysis support enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Warning: FaceAnalysis not installed.\")\n",
    "    print(\"pip install insightface\")\n",
    "# --- End HEIC/HEIF Support ---\n",
    "\n",
    "# --- Hugging Face transformers ---\n",
    "# You must install this library: pip install transformers torch\n",
    "try:\n",
    "    from transformers import pipeline, Pipeline\n",
    "    from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"CRITICAL: 'transformers' or 'torch' not found.\")\n",
    "    print(\"Please install them to run this script: pip install transformers torch\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "class ImageDataloader:\n",
    "    \"\"\"\n",
    "    Scans a directory for unique images and provides batches for processing.\n",
    "\n",
    "    This class is implemented as a Python generator. It does not\n",
    "    inherit from torch.utils.data.DataLoader, as our use case\n",
    "    requires a simple, stateful iterator.\n",
    "    \"\"\"\n",
    "    IMAGE_EXTENSIONS: tuple = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "\n",
    "    def __init__(self, root_dir: str, batch_size: int = 32):\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"Root directory not found: {root_dir}\")\n",
    "        if batch_size <= 0:\n",
    "            raise ValueError(\"Batch size must be greater than 0\")\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # self.labels will hold the \"working state\" of all images\n",
    "        # {image_path: \"unknown\"}\n",
    "        self.labels: Dict[str, str] = {}\n",
    "        self._scan_and_deduplicate()\n",
    "\n",
    "    def _calculate_hash(self, filepath: str, block_size: int = 65536) -> str:\n",
    "        \"\"\"\n",
    "        Calculates the SHA256 hash of a file's content.\n",
    "        \"\"\"\n",
    "        sha256 = hashlib.sha256()\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                while chunk := f.read(block_size):\n",
    "                    sha256.update(chunk)\n",
    "            return sha256.hexdigest()\n",
    "        except (IOError, OSError) as e:\n",
    "            print(f\"Warning: Could not read file for hashing: {filepath}. Skipping. Error: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _scan_and_deduplicate(self):\n",
    "        \"\"\"\n",
    "        Walks the root directory, finds all unique images, and\n",
    "        populates self.labels with the default 'unknown' label.\n",
    "        \"\"\"\n",
    "        print(f\"Scanning directory: {self.root_dir}...\")\n",
    "        image_hashes: set[str] = set()\n",
    "        total_files = 0\n",
    "        duplicates_skipped = 0\n",
    "\n",
    "        for root, _, files in os.walk(self.root_dir):\n",
    "            for file in files:\n",
    "                if not file.lower().endswith(self.IMAGE_EXTENSIONS):\n",
    "                    continue\n",
    "\n",
    "                total_files += 1\n",
    "                full_path = os.path.join(root, file)\n",
    "                file_hash = self._calculate_hash(full_path)\n",
    "\n",
    "                if not file_hash:\n",
    "                    continue\n",
    "\n",
    "                if file_hash not in image_hashes:\n",
    "                    image_hashes.add(file_hash)\n",
    "                    # All images start as 'unknown'\n",
    "                    self.labels[full_path] = \"unknown\"\n",
    "                else:\n",
    "                    duplicates_skipped += 1\n",
    "\n",
    "        print(\"--- Scan Complete ---\")\n",
    "        print(f\"Total image files found: {total_files}\")\n",
    "        print(f\"Duplicate images skipped: {duplicates_skipped}\")\n",
    "        print(f\"Total unique images to process: {len(self.labels)}\")\n",
    "        if not self.labels:\n",
    "            print(\"Warning: No valid, unique images were found.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of unique images to be processed.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __iter__(self) -> Generator[Dict[str, str], None, None]:\n",
    "        \"\"\"\n",
    "        Yields batches of images as dictionaries {image_path: label}.\n",
    "        \"\"\"\n",
    "        # Get a static list of paths to iterate over\n",
    "        all_paths = list(self.labels.keys())\n",
    "        \n",
    "        for i in range(0, len(all_paths), self.batch_size):\n",
    "            batch_paths = all_paths[i : i + self.batch_size]\n",
    "            \n",
    "            # Create the batch dict\n",
    "            batch_data = {path: self.labels[path] for path in batch_paths}\n",
    "            \n",
    "            if batch_data:\n",
    "                yield batch_data\n",
    "\n",
    "\n",
    "class ImageClassifier:\n",
    "    \"\"\"\n",
    "    Uses a \"waterfall\" method to classify images from a dataloader\n",
    "    using multiple, chained AI models.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader: ImageDataloader, output_dir: str = \"output\"):\n",
    "        self.dataloader = dataloader\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # this variable save final prediction\n",
    "        self.processed_images = {}\n",
    "\n",
    "        # 1. Determine the device\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.pipeline_device = 0 if self.device == torch.device('cuda') else -1\n",
    "        print(f\"Using device: {self.device} (Pipeline device: {self.pipeline_device})\")\n",
    "        \n",
    "        self.output_paths = {\n",
    "            \"people\": os.path.join(output_dir, \"people\"),\n",
    "            \"view\": os.path.join(output_dir, \"view\"),\n",
    "            \"screen_shot\": os.path.join(output_dir, \"screen_shot\"),\n",
    "            \"unknown\": os.path.join(output_dir, \"unknown\")\n",
    "        }\n",
    "        self._create_output_dirs()\n",
    "        \n",
    "        # --- Load Models in __init__ ---\n",
    "        print(\"Loading models...\")\n",
    "        \n",
    "        # Stage 1: Face Detector \n",
    "        self.retinaface_model = self.load_retinaface_model()\n",
    "        self.detr_pipeline = self.load_detr_pipeline()\n",
    "\n",
    "        # Stage 2: View Detector \n",
    "        self.clip_pipeline = self.load_clip_pipeline()\n",
    "\n",
    "        print(\"Model loading complete.\")\n",
    "\n",
    "\n",
    "    def _create_output_dirs(self):\n",
    "        \"\"\"Creates the output directories if they don't exist.\"\"\"\n",
    "        print(f\"Ensuring output directories exist at: {self.output_dir}\")\n",
    "        for path in self.output_paths.values():\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "    def _move_file(self, batch_data: Dict[str, str], action='move'):\n",
    "        \"\"\"\n",
    "        batch_data: dict {image_path: label}\n",
    "\n",
    "        Moves a batch of image files to their classified directories.\n",
    "        \"\"\"\n",
    "        assert action in ['move', 'copy']\n",
    "        # Iterate over each image path and its assigned label in the dictionary\n",
    "        for image_path, new_label in batch_data.items():\n",
    "            try:\n",
    "                # 1. Get destination directory. Default to 'unknown' if label is invalid.\n",
    "                dest_dir = self.output_paths.get(new_label, self.output_paths[\"unknown\"])\n",
    "                \n",
    "                # 2. Get the base filename from the full path\n",
    "                filename = os.path.basename(image_path)\n",
    "                \n",
    "                # 3. Create the full destination path\n",
    "                dest_path = os.path.join(dest_dir, filename)\n",
    "                \n",
    "\n",
    "                # 5. Move the file\n",
    "                if action=='move':\n",
    "                    shutil.move(image_path, dest_path)\n",
    "                else:\n",
    "                    shutil.copy2(image_path, dest_path)\n",
    "\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found, cannot move: {image_path}\")\n",
    "            except PermissionError:\n",
    "                print(f\"Permission denied, cannot move: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to move {image_path}: {e}\")\n",
    "\n",
    "\n",
    "    def _display_batch(self, batch_data: Dict[str, str], show_image=False):\n",
    "        \"\"\"\n",
    "        Displays a summary of batch data (category counts) and optionally\n",
    "        renders each image with its category as the title.\n",
    "\n",
    "        Args:\n",
    "            batch_data (Dict[str, str]): Dictionary where keys are file paths \n",
    "                                        and values are the categories/labels.\n",
    "            show_image (bool): A flag to control whether to display images.\n",
    "        \"\"\"\n",
    "        # --- Batch Summary Section ---\n",
    "        \n",
    "        # Use collections.Counter to efficiently count the occurrences of each \n",
    "        # unique value (category) in the batch_data dictionary.\n",
    "        value_counts = Counter(batch_data.values())\n",
    "        \n",
    "        print(\"Counts for each unique value in this batch:\")\n",
    "        \n",
    "        # Loop through the resulting Counter object (value_counts.items())\n",
    "        for value, count in value_counts.items():\n",
    "            # Prints each unique value and its total count\n",
    "            print(f\"  Image category '{value}': {count} time(s)\")\n",
    "            \n",
    "        print(\"-----------------------------------------\")\n",
    "        \n",
    "        # --- Image Display Section ---\n",
    "        \n",
    "        # This entire block is conditional. It only runs if show_image=True\n",
    "        if show_image:\n",
    "            for key in batch_data:\n",
    "                # Print the file path being processed\n",
    "                print(key)\n",
    "                plt.title(batch_data[key])\n",
    "                plt.imshow(Image.open(key).convert('RGB'))\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "    def classify_images(self):\n",
    "        \"\"\"\n",
    "        The main classification loop (orchestrator).\n",
    "        Iterates through all batches and applies the waterfall logic.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Starting Image Classification Waterfall ---\")\n",
    "        total_batches = (len(self.dataloader) + self.dataloader.batch_size - 1) // self.dataloader.batch_size\n",
    "        \n",
    "        for i, initial_batch in enumerate(self.dataloader):\n",
    "            print(f\"\\nProcessing Batch {i+1} / {total_batches} (Size: {len(initial_batch)})...\")\n",
    "            \n",
    "            remaining_batch = initial_batch.copy()\n",
    "            # --- STAGE 0: Detect screen shot ---\n",
    "            remaining_batch = self.check_screen_shot(remaining_batch)\n",
    "\n",
    "            # --- STAGE 1: Detect faces ---\n",
    "            if self.retinaface_model:\n",
    "                remaining_batch = self.detect_human_detr_pipeline(remaining_batch, self.detr_pipeline)\n",
    "            \n",
    "            # --- STAGE 1: Detect people ---\n",
    "            if self.retinaface_model:\n",
    "                remaining_batch = self.detect_with_RetinaFace(remaining_batch, self.retinaface_model)\n",
    "\n",
    "            # --- STAGE 2: View Models ---\n",
    "            if self.clip_pipeline:\n",
    "                remaining_batch = self.detect_view_clip_pipeline(\n",
    "                    remaining_batch, self.clip_pipeline,\n",
    "                    target_label=\"view\",\n",
    "                    prompts=[\"a photo of a landscape\", \"a beautiful view\", \"a flower\", \"a photo of food\", \"a city skyline\", \"a beach\", \"mountains\", \"a forest\"]\n",
    "                )\n",
    "\n",
    "\n",
    "            self._move_file(remaining_batch, 'copy')\n",
    "            self.processed_images |=remaining_batch\n",
    "            print(f\"Batch {i+1} complete.\")\n",
    "        \n",
    "        self._display_batch(self.processed_images)\n",
    "\n",
    "        print(\"\\n--- Image Classification Finished ---\")\n",
    "\n",
    "    # --- Specific Model Classification Methods ---\n",
    "    # --- Specific retinaface Model ---\n",
    "    def load_retinaface_model(self):\n",
    "        # try:\n",
    "        #     app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "        #     app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "        #     print(\"Loaded: retinaface\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"CRITICAL: Failed to load retinaface. {e}\")\n",
    "        #     app = None\n",
    "\n",
    "        app = FaceAnalysis(name=\"buffalo_l\")  # uses RetinaFace + ArcFace\n",
    "        app.prepare(ctx_id=0, det_size=(640, 640))  # GPU: ctx_id=0\n",
    "        return app\n",
    "    \n",
    "    def detect_with_RetinaFace(self, batch_data, model, target_label='people'):\n",
    "        \"\"\"\n",
    "        batch_data: dict {image_path: label}\n",
    "        model: RetinaFace model (insightface FaceAnalysis)\n",
    "\n",
    "        Processes only images labeled 'unknown'.\n",
    "        Returns updated batch_data with detections.\n",
    "        \"\"\"\n",
    "        updated_data = batch_data.copy()\n",
    "\n",
    "        # 1️⃣ Filter for unknown images\n",
    "        unknown_items = [(path, label) for path, label in batch_data.items() if label == \"unknown\"]\n",
    "        if not unknown_items:\n",
    "            return updated_data\n",
    "        \n",
    "        #print(f\"\\nProcessing {len(unknown_items)} 'unknown' images using the RetinaFace model...\")\n",
    "\n",
    "        image_paths = [p for p, _ in unknown_items]\n",
    "\n",
    "        # 2️⃣ Load all images once\n",
    "        loaded_images = {}\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_bgr = np.array(img)[:, :, ::-1]  # RGB → BGR\n",
    "                loaded_images[img_path] = img_bgr\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error reading {img_path}: {e}\")\n",
    "                updated_data[img_path] = \"invalid\"\n",
    "\n",
    "        update_count=0\n",
    "        # 3️⃣ Run inference per image (insightface doesn't support batch)\n",
    "        for img_path, img_bgr in loaded_images.items():\n",
    "            faces = model.get(img_bgr)  # must be called one by one\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                updated_data[img_path] = target_label\n",
    "                update_count+=1\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(unknown_items)} images using detr. Updated {update_count} labels to '{target_label}'.\")\n",
    "        return updated_data\n",
    "\n",
    "    # --- Specific detr Model ---\n",
    "    def load_detr_pipeline(self):\n",
    "        try:\n",
    "            model = \"facebook/detr-resnet-50\"\n",
    "            detr_pipeline = pipeline(\"object-detection\", model=model, device=self.pipeline_device)\n",
    "            print(\"Loaded: facebook/detr-resnet-50\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load DETR. {e}\")\n",
    "            detr_pipeline = None\n",
    "        return detr_pipeline\n",
    "\n",
    "    def detect_human_detr_pipeline(self, batch_data: Dict[str, str], detr_pipeline: Any, target_label='people') -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Detects humans ('person' label) in ALL images labeled 'unknown' using the \n",
    "        Hugging Face pipeline in a single batch operation and updates the labels.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            detr_pipeline (transformers.Pipeline): The loaded DETR object detection pipeline.\n",
    "            confidence_threshold (float): Minimum confidence for a detection to be considered.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        # DETR is trained on COCO, where the label for a human is 'person'\n",
    "        PERSON_LABEL = 'person' \n",
    "        confidence_threshold = 0.9\n",
    "\n",
    "        if detr_pipeline is None:\n",
    "            print(\"ERROR: Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        # print(f\"\\nProcessing all {len(unknown_paths)} 'unknown' images using the detr pipeline...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # The pipeline handles moving data to the device defined during load.\n",
    "        # We pass the list of PIL images directly.\n",
    "        try:\n",
    "            # The result is a list of lists: [[det1, det2, ...], [det1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = detr_pipeline(batch_images)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        update_count = 0\n",
    "        # 3. Post-process the results\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            is_human_detected = False\n",
    "            \n",
    "            # image_results is a list of dictionaries (one for each detection)\n",
    "            for detection in image_results:\n",
    "                # The pipeline provides the score and the label (e.g., 'person')\n",
    "                if detection['score'] >= confidence_threshold and detection['label'] == PERSON_LABEL:\n",
    "                    is_human_detected = True\n",
    "                    # print(f\"✅ Detected {PERSON_LABEL} in: {image_path} with score {detection['score']:.2f}\")\n",
    "                    break # Found a person, no need to check other detections for this image\n",
    "\n",
    "            if is_human_detected:\n",
    "                batch_data[image_path] = target_label\n",
    "                update_count+=1\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using detr. Updated {update_count} labels to '{target_label}'.\")\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "    # --- Specific clip Model ---\n",
    "    def load_clip_pipeline(self):\n",
    "        \"\"\"\n",
    "        Loads the CLIP zero-shot classification pipeline.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            clip_pipeline = pipeline(\n",
    "                \"zero-shot-image-classification\",\n",
    "                model=\"openai/clip-vit-large-patch14\",\n",
    "                device=self.pipeline_device  \n",
    "            )\n",
    "            print(\"Loaded: clip-vit-large-patch14\")\n",
    "            return clip_pipeline  # <-- FIX: You must return the loaded pipeline\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL: Failed to load CLIP. {e}\")\n",
    "            return None # Return None on failure\n",
    "\n",
    "    def detect_view_clip_pipeline(self, batch_data: Dict[str, str], clip_pipeline: Any, target_label: str, prompts: List[str], confidence_threshold: float = 0.80) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classifies images labeled 'unknown' using the CLIP pipeline and a list of prompts.\n",
    "        \n",
    "        If the top-scoring prompt meets the confidence threshold, the image label\n",
    "        is updated to the single `target_label`.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            clip_pipeline (transformers.Pipeline): The loaded CLIP pipeline.\n",
    "            target_label (str): The new label to assign if a match is found (e.g., 'view').\n",
    "            prompts (list): A list of candidate labels to check against (e.g., \"a flower\").\n",
    "            confidence_threshold (float): Minimum confidence for a classification.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        if clip_pipeline is None:\n",
    "            print(\"ERROR: CLIP Pipeline is not loaded. Cannot process data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 1. Identify images to process, load, and validate paths\n",
    "        unknown_paths = [path for path, label in batch_data.items() if label == 'unknown']\n",
    "        \n",
    "        if not unknown_paths:\n",
    "            print(\"No images labeled 'unknown' found for CLIP processing. Returning original data.\")\n",
    "            return batch_data\n",
    "        \n",
    "        # print(f\"\\nProcessing {len(unknown_paths)} 'unknown' images using CLIP with {len(prompts)} prompts...\")\n",
    "\n",
    "        # Load PIL Images for the pipeline\n",
    "        batch_images: List[Image.Image] = []\n",
    "        valid_paths: List[str] = []\n",
    "        for path in unknown_paths:\n",
    "            try:\n",
    "                if not os.path.exists(path):\n",
    "                    print(f\"⚠️ Warning: Image not found at {path}. Skipping.\")\n",
    "                    continue\n",
    "                batch_images.append(Image.open(path).convert(\"RGB\"))\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ An error occurred loading {path}: {e}. Skipping.\")\n",
    "\n",
    "        if not valid_paths:\n",
    "            print(\"No valid images could be loaded for CLIP. Returning original data.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 2. Perform single batch inference\n",
    "        # We pass the list of PIL images and the candidate labels\n",
    "        try:\n",
    "            # The result is a list of lists: [[class1, class2, ...], [class1, ...], ...]\n",
    "            results: List[List[Dict[str, Any]]] = clip_pipeline(\n",
    "                batch_images, \n",
    "                candidate_labels=prompts\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"\\nRUNTIME ERROR during CLIP pipeline execution: {e}\")\n",
    "            print(\"The batch might be too large for available memory.\")\n",
    "            return batch_data\n",
    "\n",
    "        # 3. Post-process the results\n",
    "        update_count = 0\n",
    "        for idx, image_results in enumerate(results):\n",
    "            image_path = valid_paths[idx]\n",
    "            \n",
    "            # The pipeline returns all prompts, sorted by score.\n",
    "            # We only care about the top-scoring one.\n",
    "            top_detection = image_results[0]\n",
    "            \n",
    "            # Check if the top score meets our threshold.\n",
    "            # Since the pipeline only returns labels from our `prompts` list,\n",
    "            # we know the label is one we are looking for.\n",
    "            if top_detection['score'] >= confidence_threshold:\n",
    "                # print(f\"✅ Classified {image_path} as '{top_detection['label']}' (score: {top_detection['score']:.2f}). Setting label to '{target_label}'.\")\n",
    "                \n",
    "                # Update the label to the generic target_label\n",
    "                batch_data[image_path] = target_label\n",
    "                update_count += 1\n",
    "            else:\n",
    "                # The top score was too low, so we \"leave it\" (it remains 'unknown')\n",
    "                pass\n",
    "\n",
    "        print(f\"\\nSuccessfully processed {len(valid_paths)} images using CLIP. Updated {update_count} labels to '{target_label}'.\")\n",
    "        return batch_data\n",
    "\n",
    "    # --- Specific screen shot Model ---\n",
    "    def check_screen_shot(self, batch_data: Dict[str, str], target_label='screen_shot') -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classifies images labeled 'unknown' using a two-stage heuristic method.\n",
    "        \n",
    "        1. Disqualifies images with camera-specific EXIF data.\n",
    "        2. Qualifies images that lack camera EXIF and match known iPhone screen resolutions.\n",
    "        \n",
    "        Updated the image label in batch_data to `target_label` or 'photo'.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            target_label (str): The new label to assign if a match is found (e.g., 'screen_shot').\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- Start of self-contained logic ---\n",
    "        \n",
    "        # 1. Define necessary constants and lookups\n",
    "        \n",
    "        # We need to get the string names for the numeric EXIF tag IDs\n",
    "        # This creates a lookup like {271: 'Make', 272: 'Model', ...}\n",
    "        try:\n",
    "            TAGS_LOOKUP = {v: k for k, v in ExifTags.TAGS.items()}\n",
    "        except AttributeError:\n",
    "            # Fallback in case ExifTags.TAGS isn't available (though it should be)\n",
    "            TAGS_LOOKUP = {}\n",
    "\n",
    "        # EXIF tags that strongly indicate a photo was taken by a camera\n",
    "        CAMERA_EXIF_TAGS = {\n",
    "            \"Make\", \"Model\", \"ExposureTime\", \"FNumber\", \n",
    "            \"ISOSpeedRatings\", \"DateTimeOriginal\", \"LensModel\", \"GPSInfo\"\n",
    "        }\n",
    "        \n",
    "        # A list of (width, height) tuples for known iPhone physical resolutions\n",
    "        _IPHONE_RESOLUTIONS_BASE = [\n",
    "            (750, 1334),   # iPhone 6 / 6S / 7 / 8 / SE (2nd/3rd gen)\n",
    "            (1080, 1920),  # iPhone 6+ / 6S+ / 7+ / 8+ (actual rendered resolution)\n",
    "            (640, 1136),   # iPhone SE (1st gen) / 5S\n",
    "            (1125, 2436),  # iPhone X / XS / 11 Pro (5.8″)\n",
    "            (828, 1792),   # iPhone XR / 11 (6.1″)\n",
    "            (1242, 2688),  # iPhone XS Max / 11 Pro Max (6.5″)\n",
    "            (1080, 2340),  # iPhone 12 mini / 13 mini (5.4″)\n",
    "            (1170, 2532),  # iPhone 12 / 12 Pro / 13 / 13 Pro / (14 6.1″) / (15 6.1″) — verify model variant\n",
    "            (1284, 2778),  # iPhone 12 Pro Max / 13 Pro Max / (14 Plus) / (15 Plus) — verify model variant\n",
    "            (1179, 2556),  # iPhone 14 Pro (6.1″) / iPhone 15 Pro (6.1″) — spec confirms 2556×1179. :contentReference[oaicite:18]{index=18}\n",
    "            (1206, 2622),  # iPhone 16 Pro (6.3″) / iPhone 17 (6.3″) — confirms 2622×1206. :contentReference[oaicite:19]{index=19}\n",
    "            (1320, 2868),  # iPhone 16 Pro Max / iPhone 17 Pro Max (6.9″) — spec confirm 2868×1320. :contentReference[oaicite:20]{index=20}\n",
    "        ]\n",
    "        \n",
    "        # Create the final set we'll check against\n",
    "        # Add both (W, H) and (H, W) to catch portrait/landscape\n",
    "        IPHONE_SCREEN_SIZES = set()\n",
    "        for w, h in _IPHONE_RESOLUTIONS_BASE:\n",
    "            IPHONE_SCREEN_SIZES.add((w, h))\n",
    "            IPHONE_SCREEN_SIZES.add((h, w))\n",
    "            \n",
    "        # --- End of self-contained logic ---\n",
    "        \n",
    "        update_count = 0\n",
    "        # Iterate over a static list of keys to safely modify the dictionary\n",
    "        for image_path in list(batch_data.keys()):\n",
    "            label = batch_data[image_path]\n",
    "            \n",
    "            # Only process images labeled 'unknown'\n",
    "            if label != 'unknown':\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    \n",
    "                    # --- Heuristic 1: Check for DISQUALIFYING camera EXIF data ---\n",
    "                    # We default to assuming it's not a photo until proven.\n",
    "                    is_photo = False\n",
    "                    \n",
    "                    # Suppress PIL.Image.DecompressionBombWarning if images are very large\n",
    "                    # This check is basic; for production, you'd set Image.MAX_IMAGE_PIXELS\n",
    "                    \n",
    "                    exif_data = img.getexif()\n",
    "                    if exif_data:\n",
    "                        for tag_id, value in exif_data.items():\n",
    "                            # Look up the tag name (e.g., 271 -> 'Make')\n",
    "                            tag_name = TAGS_LOOKUP.get(tag_id, tag_id)\n",
    "                            \n",
    "                            if tag_name in CAMERA_EXIF_TAGS:\n",
    "                                is_photo = True\n",
    "                                break\n",
    "                    \n",
    "                    if is_photo:\n",
    "                        # This is almost certainly a camera photo.\n",
    "                        # Re-label it and stop processing this image.\n",
    "                        batch_data[image_path] = 'photo'\n",
    "                        continue \n",
    "\n",
    "                    # --- Heuristic 2: Check for QUALIFYING screen dimensions ---\n",
    "                    # This code only runs if the image had NO EXIF data, \n",
    "                    # or had EXIF data but no camera-specific tags.\n",
    "                    dimensions = img.size  # (width, height)\n",
    "                    \n",
    "                    if dimensions in IPHONE_SCREEN_SIZES:\n",
    "                        # Matched a known resolution and wasn't a photo\n",
    "                        batch_data[image_path] = target_label\n",
    "                        update_count+=0\n",
    "                    # else:\n",
    "                        # It remains 'unknown' if it doesn't match\n",
    "            \n",
    "\n",
    "            except Image.DecompressionBombError:\n",
    "                print(f\"Warning: Image {image_path} is too large to process safely (DecompressionBomb). Labeling as 'error'.\")\n",
    "                batch_data[image_path] = 'processing_error'\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: Image file not found at {image_path}. Labeling as 'error'.\")\n",
    "                batch_data[image_path] = 'file_not_found'\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not process image {image_path}. Error: {e}\")\n",
    "                batch_data[image_path] = 'processing_error'\n",
    "        \n",
    "        print(f\"\\nSuccessfully processed {len(batch_data)} images using CLIP. Updated {update_count} labels to '{target_label}'.\")\n",
    "\n",
    "        return batch_data\n",
    "\n",
    "\n",
    "    def place_hold(self, batch_data: Dict[str, str], target_label='screen_shot') -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classifies images labeled 'unknown' using the proposed method.\n",
    "        \n",
    "        Updated the image label in batch_data to `target_label`.\n",
    "\n",
    "        Args:\n",
    "            batch_data (dict): A dictionary of {image_path: label}.\n",
    "            target_label (str): The new label to assign if a match is found (e.g., 'screen_shot').\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated batch_data dictionary.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test_dir = r\"D:\\images\\HockingHills\"\n",
    "test_dir = r\"D:\\images\\images\"\n",
    "output = r\"D:\\images\\output\"\n",
    "\n",
    "\n",
    "# 1. Instantiate the Dataloader\n",
    "# Using a small batch size for the example\n",
    "dataloader = ImageDataloader(root_dir=test_dir, batch_size=32)\n",
    "\n",
    "classifier = ImageClassifier(dataloader=dataloader, output_dir=output)\n",
    "\n",
    "try:\n",
    "    classifier.classify_images()\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during classification: {e}\")\n",
    "    print(\"This can happen if you are offline or models are unavailable.\")\n",
    "\n",
    "# 5. Print a summary\n",
    "print(\"\\n--- Final Output Summary ---\")\n",
    "try:\n",
    "    for category in os.listdir(output):\n",
    "        category_path = os.path.join(output, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            files = os.listdir(category_path)\n",
    "            print(f\"Files in '{category}': {len(files)} {files}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Output directory 'classification_output' not found. Did the script run?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
